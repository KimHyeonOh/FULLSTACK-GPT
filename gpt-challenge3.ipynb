{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Challenge #3\n",
    "앞서 배운 메모리 클래스 중 하나를 사용하는 메모리로 LCEL 체인을 구현합니다.\n",
    "이 체인은 영화 제목을 가져와 영화를 나타내는 세 개의 이모티콘으로 응답해야 합니다. (예: \"탑건\" -> \"🛩️👨‍✈️🔥\". \"대부\" -> \"👨‍👨‍👦🔫🍝\").\n",
    "항상 세 개의 이모티콘으로 답장하도록 FewShotPromptTemplate 또는 FewShotChatMessagePromptTemplate을 사용하여 체인에 예시를 제공하세요.\n",
    "메모리가 작동하는지 확인하려면 체인에 두 개의 영화에 대해 질문한 다음 다른 셀에서 체인에 먼저 질문한 영화가 무엇인지 알려달라고 요청하세요.\n",
    "\n",
    "Hint.\n",
    "예시 제공\n",
    "요구조건에 맞는 답변 형식을 생성하도록 적절한 예시를 만들고, FewShotPromptTemplate 또는 FewShotChatMessagePromptTemplate를 이용하여 LLM에게 예시를 제공하세요.\n",
    "자세한 사용법은 다음 공식 문서를 참고해보세요\n",
    "Few-shot prompt templates\n",
    "Few-shot examples for chat models\n",
    "메모리 활용\n",
    "ConversationBufferMemory 등 강의에서 배운 메모리 중 하나를 사용하여 이전 대화 기록을 기억하고 기록을 이용한 답변을 제공할 수 있도록 합니다.\n",
    "채팅 형식의 메모리 기록을 프롬프트에 추가하고 싶을 때는 MessagesPlaceholder를 이용하세요. (공식문서 예시)\n",
    "RunnablePassthrough를 활용하면 LCEL 체인을 구현할 때 메모리 적용을 쉽게 할 수 있습니다. RunnablePassthrough는 메모리를 포함한 데이터를 체인의 각 단계에 전달하는 역할을 합니다. (강의 #5.7 1:04~ 참고)\n",
    "\"\"\"\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature= 0.1,\n",
    "    streaming=False,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"탑건\", \"output\": \"🛩️👨‍✈️🔥\"},\n",
    "    {\"input\": \"대부\", \"output\": \"👨‍👨‍👦🔫🍝\"},\n",
    "    {\"input\": \"어벤져스\", \"output\": \"🛡️🧙‍♂️🧟‍♂️\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"영화 제목: {input}\\n이모티콘: {output}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"다음 영화 제목을 세 개의 이모티콘으로 나타내세요.\",\n",
    "    suffix=\"영화 제목: {movie_title}\\n이모티콘:\",\n",
    "    input_variables=[\"movie_title\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcel_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=few_shot_prompt,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 응답: 🛩️👨‍✈️🔥\n"
     ]
    }
   ],
   "source": [
    "response1 = lcel_chain.run(movie_title=\"탑건\")\n",
    "print(\"첫 번째 응답:\", response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 번째 응답: 🌿🌎🔵\n"
     ]
    }
   ],
   "source": [
    "response2 = lcel_chain.run(movie_title=\"아바타\")\n",
    "print(\"두 번째 응답:\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 질문: 아바타\n"
     ]
    }
   ],
   "source": [
    "previous_question = memory.chat_memory.messages[-2]  # 마지막 HumanMessage\n",
    "print(\"이전 질문:\", previous_question.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 질문: 🛩️👨‍✈️🔥\n"
     ]
    }
   ],
   "source": [
    "previous_question = memory.chat_memory.messages[-3]  # 마지막 HumanMessage\n",
    "print(\"이전 질문:\", previous_question.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 질문: 탑건\n"
     ]
    }
   ],
   "source": [
    "previous_question = memory.chat_memory.messages[-4]  # 마지막 HumanMessage\n",
    "print(\"이전 질문:\", previous_question.content)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
