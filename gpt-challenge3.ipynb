{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Challenge #3\n",
    "ì•ì„œ ë°°ìš´ ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ë¡œ LCEL ì²´ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "ì´ ì²´ì¸ì€ ì˜í™” ì œëª©ì„ ê°€ì ¸ì™€ ì˜í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„¸ ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: \"íƒ‘ê±´\" -> \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\". \"ëŒ€ë¶€\" -> \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\").\n",
    "í•­ìƒ ì„¸ ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ë‹µì¥í•˜ë„ë¡ FewShotPromptTemplate ë˜ëŠ” FewShotChatMessagePromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ì— ì˜ˆì‹œë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "ë©”ëª¨ë¦¬ê°€ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ì²´ì¸ì— ë‘ ê°œì˜ ì˜í™”ì— ëŒ€í•´ ì§ˆë¬¸í•œ ë‹¤ìŒ ë‹¤ë¥¸ ì…€ì—ì„œ ì²´ì¸ì— ë¨¼ì € ì§ˆë¬¸í•œ ì˜í™”ê°€ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ë‹¬ë¼ê³  ìš”ì²­í•˜ì„¸ìš”.\n",
    "\n",
    "Hint.\n",
    "ì˜ˆì‹œ ì œê³µ\n",
    "ìš”êµ¬ì¡°ê±´ì— ë§ëŠ” ë‹µë³€ í˜•ì‹ì„ ìƒì„±í•˜ë„ë¡ ì ì ˆí•œ ì˜ˆì‹œë¥¼ ë§Œë“¤ê³ , FewShotPromptTemplate ë˜ëŠ” FewShotChatMessagePromptTemplateë¥¼ ì´ìš©í•˜ì—¬ LLMì—ê²Œ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "ìì„¸í•œ ì‚¬ìš©ë²•ì€ ë‹¤ìŒ ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”\n",
    "Few-shot prompt templates\n",
    "Few-shot examples for chat models\n",
    "ë©”ëª¨ë¦¬ í™œìš©\n",
    "ConversationBufferMemory ë“± ê°•ì˜ì—ì„œ ë°°ìš´ ë©”ëª¨ë¦¬ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ê¸°ì–µí•˜ê³  ê¸°ë¡ì„ ì´ìš©í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "ì±„íŒ… í˜•ì‹ì˜ ë©”ëª¨ë¦¬ ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•˜ê³  ì‹¶ì„ ë•ŒëŠ” MessagesPlaceholderë¥¼ ì´ìš©í•˜ì„¸ìš”. (ê³µì‹ë¬¸ì„œ ì˜ˆì‹œ)\n",
    "RunnablePassthroughë¥¼ í™œìš©í•˜ë©´ LCEL ì²´ì¸ì„ êµ¬í˜„í•  ë•Œ ë©”ëª¨ë¦¬ ì ìš©ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. RunnablePassthroughëŠ” ë©”ëª¨ë¦¬ë¥¼ í¬í•¨í•œ ë°ì´í„°ë¥¼ ì²´ì¸ì˜ ê° ë‹¨ê³„ì— ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. (ê°•ì˜ #5.7 1:04~ ì°¸ê³ )\n",
    "\"\"\"\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature= 0.1,\n",
    "    streaming=False,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"íƒ‘ê±´\", \"output\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"},\n",
    "    {\"input\": \"ëŒ€ë¶€\", \"output\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"},\n",
    "    {\"input\": \"ì–´ë²¤ì ¸ìŠ¤\", \"output\": \"ğŸ›¡ï¸ğŸ§™â€â™‚ï¸ğŸ§Ÿâ€â™‚ï¸\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"ì˜í™” ì œëª©: {input}\\nì´ëª¨í‹°ì½˜: {output}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"ë‹¤ìŒ ì˜í™” ì œëª©ì„ ì„¸ ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì„¸ìš”.\",\n",
    "    suffix=\"ì˜í™” ì œëª©: {movie_title}\\nì´ëª¨í‹°ì½˜:\",\n",
    "    input_variables=[\"movie_title\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcel_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=few_shot_prompt,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²« ë²ˆì§¸ ì‘ë‹µ: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    }
   ],
   "source": [
    "response1 = lcel_chain.run(movie_title=\"íƒ‘ê±´\")\n",
    "print(\"ì²« ë²ˆì§¸ ì‘ë‹µ:\", response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‘ ë²ˆì§¸ ì‘ë‹µ: ğŸŒ¿ğŸŒğŸ”µ\n"
     ]
    }
   ],
   "source": [
    "response2 = lcel_chain.run(movie_title=\"ì•„ë°”íƒ€\")\n",
    "print(\"ë‘ ë²ˆì§¸ ì‘ë‹µ:\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ì „ ì§ˆë¬¸: ì•„ë°”íƒ€\n"
     ]
    }
   ],
   "source": [
    "previous_question = memory.chat_memory.messages[-2]  # ë§ˆì§€ë§‰ HumanMessage\n",
    "print(\"ì´ì „ ì§ˆë¬¸:\", previous_question.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ì „ ì§ˆë¬¸: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    }
   ],
   "source": [
    "previous_question = memory.chat_memory.messages[-3]  # ë§ˆì§€ë§‰ HumanMessage\n",
    "print(\"ì´ì „ ì§ˆë¬¸:\", previous_question.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ì „ ì§ˆë¬¸: íƒ‘ê±´\n"
     ]
    }
   ],
   "source": [
    "previous_question = memory.chat_memory.messages[-4]  # ë§ˆì§€ë§‰ HumanMessage\n",
    "print(\"ì´ì „ ì§ˆë¬¸:\", previous_question.content)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
