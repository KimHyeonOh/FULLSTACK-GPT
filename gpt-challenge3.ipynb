{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Challenge #3\n",
    "ì•ì„œ ë°°ìš´ ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ë¡œ LCEL ì²´ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "ì´ ì²´ì¸ì€ ì˜í™” ì œëª©ì„ ê°€ì ¸ì™€ ì˜í™”ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„¸ ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: \"íƒ‘ê±´\" -> \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\". \"ëŒ€ë¶€\" -> \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\").\n",
    "í•­ìƒ ì„¸ ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ ë‹µì¥í•˜ë„ë¡ FewShotPromptTemplate ë˜ëŠ” FewShotChatMessagePromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ì— ì˜ˆì‹œë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "ë©”ëª¨ë¦¬ê°€ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ì²´ì¸ì— ë‘ ê°œì˜ ì˜í™”ì— ëŒ€í•´ ì§ˆë¬¸í•œ ë‹¤ìŒ ë‹¤ë¥¸ ì…€ì—ì„œ ì²´ì¸ì— ë¨¼ì € ì§ˆë¬¸í•œ ì˜í™”ê°€ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ë‹¬ë¼ê³  ìš”ì²­í•˜ì„¸ìš”.\n",
    "\n",
    "Hint.\n",
    "ì˜ˆì‹œ ì œê³µ\n",
    "ìš”êµ¬ì¡°ê±´ì— ë§ëŠ” ë‹µë³€ í˜•ì‹ì„ ìƒì„±í•˜ë„ë¡ ì ì ˆí•œ ì˜ˆì‹œë¥¼ ë§Œë“¤ê³ , FewShotPromptTemplate ë˜ëŠ” FewShotChatMessagePromptTemplateë¥¼ ì´ìš©í•˜ì—¬ LLMì—ê²Œ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
    "ìì„¸í•œ ì‚¬ìš©ë²•ì€ ë‹¤ìŒ ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”\n",
    "Few-shot prompt templates\n",
    "Few-shot examples for chat models\n",
    "ë©”ëª¨ë¦¬ í™œìš©\n",
    "ConversationBufferMemory ë“± ê°•ì˜ì—ì„œ ë°°ìš´ ë©”ëª¨ë¦¬ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ê¸°ì–µí•˜ê³  ê¸°ë¡ì„ ì´ìš©í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "ì±„íŒ… í˜•ì‹ì˜ ë©”ëª¨ë¦¬ ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•˜ê³  ì‹¶ì„ ë•ŒëŠ” MessagesPlaceholderë¥¼ ì´ìš©í•˜ì„¸ìš”. (ê³µì‹ë¬¸ì„œ ì˜ˆì‹œ)\n",
    "RunnablePassthroughë¥¼ í™œìš©í•˜ë©´ LCEL ì²´ì¸ì„ êµ¬í˜„í•  ë•Œ ë©”ëª¨ë¦¬ ì ìš©ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. RunnablePassthroughëŠ” ë©”ëª¨ë¦¬ë¥¼ í¬í•¨í•œ ë°ì´í„°ë¥¼ ì²´ì¸ì˜ ê° ë‹¨ê³„ì— ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. (ê°•ì˜ #5.7 1:04~ ì°¸ê³ )\n",
    "\"\"\"\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature= 0.1,\n",
    "    streaming=False,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
