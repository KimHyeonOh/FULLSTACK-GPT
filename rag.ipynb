{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n  진 웹스터 소설\\n『키다리 아저씨』 우리말 옮김\\n\\n당신\\n\\n키다리 아저씨께\\n\\n키다리 아저씨\\n\\n1장. “짱 나는 수요일” \\n(원문→“우울한 수요일”)\\n\\n매월 첫 번째 수요일은 너무도 끔직한 날이었다. 두려움 가득 그날을 기다렸다가 급히 서둘며 용기와 망각(잊음)으로 견디는 그런 날 말이다.\\n모든 바닥은 먼지 하나 없이 닦여져야 하고, 모든 의자엔 낙서 하나 없어야 했고, 모든 침대엔 구김 한 번 없어야 했다.\\n꿈틀대는 97명의 어린 고아들이 때밀이로 박박 때를 밀고 빗질을 하고 다름 질을 한 새 옷에 단추를 단단히 잠겨야했다.\\n또한 이 97명의 아이들은 예법들을 기억해야했고 만약 평의원(=고아원을 금전적으로 지원하는 분들)님들이 물으실 경우, \\n“네, 선생님.”\\n또는,\\n“아니오, 선생님.”\\n라고 대답해야했다. \\n고통스런 시간이었다. 특히나 고아들 중 가장 나이가 많은, 가련한 ‘제루샤 에벗’(여주인공이름. 에벗은 남자이름임)에게 있어서 그 시간은 자신이 모든 짐을 짊어져야하는 그런 시간이었다. \\n이전의 것과 마찬가지로, 이 특별했던 첫 번째 수요일도 마침내 꾸억꾸억 종료를 향해 나아가고 있었다. \\n고아원 손님들을 위해 샌드위치들을 다 만든 후 식료품저장실을 벗어나, 제루샤(여주인공 이름)는 자신의 정규 일을 마무리 짓기 위해 위층으로 향했다. \\n특히나 ‘바’(원문→에프) 방에 무척 신경을 기울였는데, 그 방에는 4잘부터 7살에 이르는 11명의 어린 꼬마들이 일렬로 널어진 11개의 간이침대에 거주하고 있는 방이었다. \\n제루샤는 아이들을 모은 다음, 구겨진 옷들을 곱게 펴주고 코를 닦아준 다음 그들이 질서 있게 줄을 이루며 식당으로 출발하도록 했다. 그 애들에게, 빵과 우유 그리고 자두 푸딩(서양과자)과 함께 축복받은 30분을 약속해주고 있는 식당 말이다.  \\n그런 다음 제루샤(여주인공이름)는 창가 쪽 의자 위에 앉아 고동치는 관자놀이(귀와 눈 사이에, 오목하게 들어간 곳)를 차가운 창문에 기대었다. \\n이날 아침 5시부터 한시도 앉지 못했더랬다. 사람들이 시키는 일을 하느라, 신경질적인 보모가 꾸짖고 다그치는 통에 말이다.\\n리펫 원장은, 평의원(=이사)들과 부인 방문객들과 얼굴을 마주하며 차분하고 위엄 있게 행동했지만 무대 뒤에선 항상 그런 건 아니었기 때문이다.  \\n제루샤는, 고아원 경계 자국을 내고 있는 키 큰 철제 울타리 너머로, 넓게 뻗은 언 잔디밭 저쪽을 바라다보았다. \\n그 아래로는 시골의 사유지들이 섞인 울퉁불퉁한 산등성이들이 보였다.\\n마을의 뾰족탑들이 듬성한 나무들 가운데로 높게 솟아나 있었다. \\n어쨌든 그날은… 아주 성공적으로 끝이 났다. 적어도 제루샤(여주인공이름)가 아는 한은 말이다. \\n평의원 분들과 함께 방문한 후원인 분들은 한 바퀴 둘러본 후 제출된 보고서들을 읽고 차(마시는 차)를 한 잔씩 했다.\\n그리고 이젠 그들도 서둘러 자신들을 기다리는 활기찬 벽난로 가가 있는 집으로 돌아들 가고 있는 중이었다. \\n다음 달에 있을 그들의 방문이 어떤 성가심을 주는지 망각한 채 말이다. \\n제루샤는 호기심 가득 그들을 쳐다보며 몸을 숙이고 있었다… 동경의 눈, 횃불… 고아원 정문을 굴러나가고 있는 마차들과 자동차들의 행렬들.   \\n상상 속에서, 제루샤는 첫 번째 마차를 따라 산중턱에 있던 어느 큰 저택으로 향했다. \\n자신이 마차 좌석에 몸을 파묻고는 무심한 듯 “그만 집으로”라고 마부에게 중얼거리고 있는, 모피 코트와 깃털로 테두리를 다듬은 벨벳 모자를 한 자신의 모습을 그려보았다. \\n하지만 그 큰 집 문지방에 막 다다랐을 때 형상(그림)이 점점 흐려졌다. \\n제류샤는 상상력을 가졌다… 풍부한 상상력, 그래서인지 리렛 원장은 제루샤에게 말하길, “주의하지 않음 곤란에 부딪힐 거”라고…, \\n하지만 그 예리한 상상력에도 불구하고, 도무지 그 귀부인 들어설 저택의 현관문 너머는 상상이 잘 안 되었다. \\n불쌍하고, 열성적이고, 모험적인 고아 제루샤는, 이제 17살이었다. \\n그녀는 결코 평범한 집에 발을 들여놓아본 적이 없었다. 그래서 도무지 다른 인류, 그러니까 고아원과는 전혀 일면식이 없는 다른 인류가 어떤 일상의 생활을 영위하는지 상상을 해볼 수 없었던 것이다. \\n\\n(▼아래는 고아원 합창단 소년이 장난으로 노래 부르는 소리)\\n〈제―루―샤  에―벗\\n부른다\\n원―장 실에서\\n내 생각엔\\n서두르는 게 좋을 듯!〉\\n\\n토미 딜런(이름 알 필요 없음. 한 번만 나오는 이름임)은 합창단에 속해 있었는데, 계단을 올라와 복도를 따라 거닐면서 노래를 부르고 있었다. \\n‘바’ 방이 가까워짐에 따라 노래는 점점 더 커지고 있었따. \\n제루샤가 창문에서 머리를 떼어 다시 현실 속 문제들로 돌아와,\\n“누가 찾는데?”라며 걱정을 한 가득 담아, 토미의 노래에 끼어들었다. \\n\\n(▼토미가 노래로 대답하는 것임)\\n〈리펫 원장이 급히 찾아, 원장실에서, \\n내 생각에 그녀가 미친 것 같아.\\n아―아―멘!〉\\n\\n토미(고아원 합창단 단원. 이름 알 필요 없음. 다시 안 나오는 이름임)가 비록 기도문 식으로 노래를 불렀지만, 하지만 그의 말투에 전혀 악의적인 기색은 찾을 수 없었다. \\n왜냐면 죄를 범한 누이가 화를 내고 있는 여간수(원장)에게 사무실로 호출 당하면 아무리 기가 센 고아원생이라도 동정심을 느끼게 마련인데 그렇지 않았고, 또한 제루샤가 토미의 팔을 홱 잡아당기거나 콧물을 너무 세게 문질러 없애긴 했지만, 그럼에도 불구하고 토미는 제루샤를 좋아했기 때문이다.    제루샤는 잠자코 향했다. \\n하지만 이마엔 벌써 두 줄이 생긴 상태였다.\\n‘뭐가 잘못된 걸까’, 하고 제루샤는 생각했다. ‘오늘 나온 샌드위치가 충분히 두덮지 못해서일까? 아님 땅콩 케이크에 땅콩 껍질이라도 들어간 걸까? 아님 틈(구멍)에 끼어 여자 방문객 한 분의 스타킹에 구멍이라도 난 걸까? 그게 아니라면… 아 설마!… 우리 ’바‘ 방에 있는 천사 아가들 중 한 명이 평의원 한 분께 말대꾸를 했나?”\\n길고 낮은 복도엔 불도 켜져 있지 않았다. \\n제루샤가 아래로 내려와 보니, 마지막 남은 평의원 한 분이 출발지점에 서 계시다가 열린 문을 통해 ‘포르트 코셰르’(현관 앞의 마차 대는 곳. 사진링크 ▶ http://me2.do/FLzLgF75 )로 걸어가고 계셨다. \\n제루샤는 흡사 그 남성의 첫인상이 키가 엄청 커다는 인상을 받았더랬다. \\n커브길에서 자신을 기다리고 있는 자동차를 향해 그 남성이 손을 흔들었다.\\n자동차가 갑자기 움직이면서 정면에서 접근함에 따라, 눈부신 헤드라이트(자동차의 불빛)가 그 분의 그림자를 벽 안쪽으로 날카롭게(원문→뚜렷이) 내던졌다. \\n이상하리만치 길게 늘어진 다리들과 팔들이 바닥을 따라 복도의 벽 천정까지 길게 그림자를 그리웠다. \\n어쩜 세상에, 저건 꼭 무지막지하게 큰 ‘장님거미’(=거미의 일종=키다리 아저씨. 키다리 아저씨의 원래 영어 제목이 ‘장님거미’임. 우리말로 하면 ‘다리가 긴 꺽다리’란 뜻임) 한 마리가 꿈틀대고 있는 것 같잖아.\\n자동차 헤드라이트에 눈살을 찌푸리다 급 웃음꽃이 핀 제루샤는 원래가 해맑은 영혼이었다. 그래서 전혀 웃기지 않은 상황 속에서도 웃음꽃을 피울 수 있었던 것이다. \\n평의원의 답답한 이미지에서 일종의 재미를 찾은 건 기대치 않은 소득이었다. \\n이 사소한 에피소드(사건)에 무척 기분이 좋아진 제루샤는 원장실로 계속 가, 미소 짓는 얼굴로 리펫 원장(이름 몰라도 됨. 다시 안 나옴) 앞에 나타났다. \\n그런데 얼씨구, 이 나이 지긋한 원장님 또한 정확히 말해 미소는 아니었지만 나름 상냥한 태도로 제루샤를 맞아주었는데, 손님을 맞이하기 위해 입었던 옷만큼이나 다채로운 표정을 짓고 계셨다. \\n“제루샤, 앉거라, 네게 해줄 말이 하나 있다.”\\n제루샤는 가장 가까이에 있던 의자에 움츠리듯 주저앉아 숨죽인 채 기다렸다. \\n좀 전 그 자동차의 불빛이 원장실의 창문을 빠르게 훑고 지나갔다. 리펫 원장이 그것을 뒤따라 흘낏 보았다.   \\n(리펫 원장의 대사→) “너도, 방금 막 나가신 신사 분을 목격했겠지?”\\n(제루샤의 대사→) “등만 본 걸요.”\\n“그는 우리 평의원들 중에서도 가장 재력과 사회적 영향력을 갖춘 사람이란다, 지금까지 상당한 액수의 금액을 고아원 기금으로 기부도 하셨고 말이다. 엄밀히 말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의 조건으로 내거셨거든.”\\n이 부분에서 제루샤의 눈이 살짝 휘둥그레졌다. \\n별난 평의원에 관해 얘기하려 자신을 원장실로 부르는 건 원장의 평소 행동이 아니었기 때문이다.\\n“이 신사 분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리 벤톤’과 ‘헨리 프리즈’ 말이다.(두 소년 모두 몰라도 되는 이름임. 다시 안 나옴) 그 애들은 미스터… 이 평의원께서 후원해 주셨고, 그 애들도 열심히 노력한 결과 나름 성공할 수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두 소년들만 초점이 맞추어져 있었단다. 고아원에 있는 여자애들에겐 전혀 관심을 표하시지 않으셨지. 여자애들이 후원을 받을만한가는 둘째치고서라도 말이다. 그래 내가 네(제루샤)게 말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.”\\n“네, 원장님.”라며 제루샤가 옹알거렸다. 이 부분에서 자신에게 뭔가 대답을 요구하는 것 같았기 때문이다. \\n“오늘 정기 모임에서는, 네(여주인공인 제루샤) 장래에 관한 얘기가 꺼내어졌다.”\\n리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에 얘기를 천천히 다시 시작했다.\\n“너도 알다시피, 대개의 경우에는, 16살이 되면(제루샤는 현재 17살임) 여기에 계속 있을 수 없다. 하지만 넌 예외였다. 네가 14살에 고아원 학교를 마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건 아니었다만. 결국 내 주장에 따라 넌 근처 마을에 있는 고등학교에 여기에 있으면서 다니는 게 허락되었고, 이제 그 마저도 다 끝마쳤다. 물론 그 이상의 교육(대학교)을 고아원에서 지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱 말이다.”\\n지난 2년 동안 제루샤가 열심히 생활했다는 사실과 고아원의 편의를 받아 첫 번째 학업 과정과 두 번째 학원 과정을 마친 사실과 아이들을 돌보며 고아원에 머물고 있는 현재의 사정을, 리펫 원장은 쭉 훑어나갔다.  \\n“이미 말한 대로, 평의원 회의에서 네 장래에 대한 안건이 상정되어 네 경력이 화제로 다루어졌단다… 아주 철저히 말이다.” \\n리펫(여자이름) 원장은 독(항아리) 안에 든 이 죄수의 유무죄를 따지려는 듯 비난하는 눈초리로 찬찬히 살폈다.  \\n그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의 성적표에서 유달리 참담했던 과목의 성적을 기억해냈기 때문은 아니었다.  \\n“물론 네게 줄 수 있는 배려들 중 하나는 네가 일을 시작할 수 있는 알맞은 직책을 찾아주는 것일 수도 있다. 하지만 네 학업성적들 중 어학관련 성적들이 워낙에 우수해서 말이다. 특히나 국어(영어) 성적이 놀랍더구나. 오늘 방문한 위원 중 한 분인 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴)는 학교 이사시기도 한데, 그녀가 말하길 네(여주인공인 제루샤) 수사학(언어의 사용을 연구하는 학문) 선생님과 얘기를 나눠보았는데 선생님이 너에 대해 호평을 하셨다고 하더라. 그리곤 프리처드 여사가 위원회에서, 네(여주인공인 제루샤)가 「짱 나는 수요일」(원문→우울한 수요일)이라고 제목 붙인 에세이 한 편도 소리 내 읽으셨단다.”\\n그 말에 제루샤(여주인공이름)의 얼굴이 붉어졌다.  \\n“그건(짱 나는 수요일이란 에세이. 고아원에 평의원들이 방문하는 날이 매월 첫 번째 수요일이라 에세이 제목에 수요일이 들어감) 네게 은덕을 베푼 시설(고아원)을 조롱하면서도 고마움은 거의 비취지 않는 글 같았다만. 그런 글에 과연 위원회에서 읽혀질 만큼 가치가 있을지 의문이었다만. 어쨌든 네(제루샤. 여주인공이름)겐 다행스럽게도, 그 자리에 계셨던, 미스터… 방금 나가셨던 그 신사 분께선… 음 그 분은 좀 무분별한 유머 감각을 가진 듯 하더구나. 그 건방진 에세이 한 편과 네 국어성적에 힘입어, 그분이 너를 대학교 보내주시겠다고 제안했단다.”\\n“대학에요?”라며 눈이 휘둥그레져선 제루샤(여주인공이름)가 말했다. \\n리펫 원장이 고개를 끄덕였다.\\n“그(키다리 아저씨)는 그 문제를 나와 상의하러 마지막까지 남아 있었던 것이다. 원래가 평의원 분들은 유별난 데가 많은데, 굳이 말하자면, 그 신사 분은 좀 상식을 벗어난 별난 데가 있다. 그 분은 네(여주인공) 창의력을 믿는다더구나. 그래서 네게 작가가 될 수 있는 교육을 받게 해줄 계획이라더라.”\\n“작가요?” 어찌나 정신이 얼얼한지 제루샤는 다만 리펫 원장의 마지막 단어(작가)를 반복하기만 했다. \\n(리펫 원장의 대사→) ”그것이 그(키다리 아저씨)의 희망이다. 그래서 어찌될 지는 곧 알게 되겠지. 일단 그 분은 네게 제법 넉넉한 용돈을 주실 게다, 거의, 용돈이라곤 생전 한 번 받아 본 적이 없는 여자애에게 있어선 아주 넉넉한 금액일 게다. 하지만 \\n(읽기 쉽게 문단을 여러 번 나눔. 모두 원장님의 긴 대사임)\\n세부적인 사항은 그 분이 짜주실 게다, 난 일일이 제안을 하고 싶지 않더라만.\\n넌 일단 여름 동안은 여기(고아원) 머물러야 한다. 그리고 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴. 학교의 이사)께서 네 채비(여행준비)를 관리해주시기로 친절하게도 제안하셨단다.\\n네 식대(식사비용)와 수업료는 대학교로 바로 지불이 될 거다, 넌 거기에 머무는 4년 동안 추가적으로 매달 70만원(원문→35달러. 이해가 쉽도록 70만원으로 해석했음. 전혀 근거가 없는 계산법임^^)을 용돈으로 받게 될 거다. \\n그 정도 용돈이면 네가 한 점 부끄러움 없이 다른 학생들과 동등하게 생활할 수 있을 게다. \\n용돈은 매달 한 번씩 그 신사 분(키다리 아저씨)의 개인 비서를 통해 네게 보내어질 게다. 넌 그 답례로 그분께 매달 한 차례 답례 편지를 써야 한다. \\n그건(답례편지)… 용돈을 주시는 것에 대한 감사 편지여서는 안 된다. 그 분은 그런 식의 언급을 극도로 싫어하시는 분이시니까. \\n하지만 넌 편지에서 네 학업의 진도와 네 매일 매일의 일상들의 세부사항들을 그 분께 말씀드려야 한다. \\n만약 네 부모님들께서 살아계셨다면 네가 적어 보냈을 그런 안부 편지를 넌 그분께 편지로 보내면 되는 거야.” (←큰 따옴표 끝. 리펫 원장의 대사 끝)\\n(리펫 원장의 대사 계속→) “네가 쓴 편지들은 존 스미스 씨 앞으로 비서(키다리 아저씨의 개인비서)를 통해 안전하게 전달될 거다. 물론 널 돕기로 한 그 분의 성함이 존 스미스란 얘기를 아니다. 어쨌든 그 분은 자신이 드러나는 걸 꺼리시니까.\\n너(여주인공)에게 그 분은 그냥 존 스미스란 얘기일 뿐이다.  \\n굳이 그 분이 네게서 편지를 요구하시는 건, 그 분이 생각하기에 문학적 표현을 기르는데 손 편지만한 게 없다 여기시기 때문이다. \\n또한 그 분은 네가 나아가는 바를 그때그때 알기를 바라신다. \\n물론 그 분이 네 편지에 답하시는 일을 결코 없을 게다. 또한 네 편지엔 그것에 대해 어떤 사소한 언급도 있어선 아니 된다. \\n그 분은 손 편지 쓰는 걸 극히 싫어하신다. 그러니 넌 그 분께 부담을 안겨선 안 돼.\\n만약 네가 퇴학을 당하는 경우와 같은 그런 어쩔 수 없는 상황이 벌어져 답장이 꼭 필요할 것 같으면, 물론 그런 일이 없어야겠지만, 넌 ‘그리그스’(영어단어 ‘그리그’는 쾌활한 사람이란 뜻임. 귀뚜라미란 뜻도 있음) 씨와 연락을 취할 수도 있을 게다. 물론 그리그스 씨는 그 분의 개인비서다. \\n매월 부쳐야하는 이 편지는 네 입장에선 절대적으로 준수해야하는 의무다. \\n스미스 씨(키다리 아저씨의 가명)가 요구하는 유일한 보상이니, 넌 그 편지들을 네가 지불하는 계산서인양 꼼꼼히 보내야한다. \\n내 생각이다만, 편지는 항상 예의발라야 되겠고 네 학업의 성과들이 반영되어야 되겠지. \\n우선은 〈존 그리어 고아원〉(←고아원이름임)의 평의원 한 분께 공손히 편지를 보내야한다는 것만 기억하고 있거라.” (←큰 따옴표 끝. 리펫 원장의 대사 끝)\\n제루샤의 두 눈은 오랫동안 문만 바라보고 있었다. \\n그녀의 머릿속엔 지금 흥분의 수레바퀴가 돌고 있어 리펫 원장의 상투적인 말투로부터 벗어나기만을 바랐을 뿐이기 때문이다. \\n제루샤가 시험 삼아 자리에서 일어나 한발작 뒷걸음을 쳐보았다. \\n그러자 리펫 원장이 손짓으로 “좀 더 기다리라”고 말했다. \\n그건 리펫 원장의 일장연설이 한 차례 더 있을 예정임을 의미했다. \\n“네게 온 이 지극히 드문 행운에 대해 네가 적절히 감사할 줄 안다고 내가 믿어도 되겠지? 도대체 이런 흔치 않은 기회를 거머쥔 여자 아이가 이 세상에 일찍이 너 말고 누가 또 있었겠니? 그러니 넌 이 점을 분명히 기억하고서 앞으로 행동을…”\\n“전(=저는)… 아, 네, 감사합니다, 원장님. 방금 생각난 건데, 제가 지금 ‘프레디 퍼킨즈’(고아 이름. 다시 안 나오는 이름임)의 바지에 헝겊을 깁다 온 걸 깜빡해서요.”\\n문이 뒤에서 “꽝!”하고 닫히자, 리펫 원장은 장황한(=긴) 연설을 하다 말고 아래턱을 쭉 내린 상태로 문을 바라보았다. \\n\\n(1장 끝)\\n\\n(여기까지가 1장 끝입니다. 2장부터는 한 달에 한 번씩 키다리 아저씨에게 보낸 편지들입니다. 이후, 1장, 2장과 같이 ‘장’은 제가 붙인 거고 원문엔 ‘장’의 구분이 없습니다.)\\n\\n\\n\\n\\n\\n\\n2장. 키다리 아저씨\\n\\n\\n\\n(옮긴이 설명 1 : 읽기 쉽게, 여주인공이 한 달에 한 번씩 키다리 아저씨에게 보낸 편지마다 새로운 ‘장’을 붙이겠습니다. 2장, 3장,...30장 이런 식으로요~ 2장=첫 번째 편지. 3장-두 번째 편지.... 30장=29번째로 보낸 편지)\\n(옮긴이 설명 2 : 이제부터는 편지입니다. 헷갈릴 수 있는데 소설이 편지의 형식입니다. 서점에 가셨을 때 키다리 아저씨 번역서를 한 번 훑어보시면 소설의 이해가 빠릅니다. 말이 편지 형식이지 인터넷으로 처음 접하면 뭔지 모를 수가 있거든요.)\\n\\n\\n\\n\\n\\n제루샤 에벗 양이\\n키다리 아저씨인 스미스 씨에게\\n보낸 편지들  \\n\\n\\n\\n(제가 추가한 제목) \\n2장. 대학교 1학년 (17세)\\n\\n\\n\\n(본문 시작)\\n퍼거슨 강당 215호에서\\n9월 24일 (여주인공 17세. 대학교 1학년)\\n\\n\\n고아들을 대학에 보내주시는 고마운 평의원(=키다리 아저씨) 분께,\\n\\n캭, 저 왔어요! 어제 열차로 자그마치 4시간 동안을 여행했답니다. 어찌나 묘한 감동이던 지요, 전엔 한 번도 기차를 타본 적이 없었걸랑요.\\n대학교(대학원을 두지 않고 대학교의 학부만 있는 대학교)는 엄청 커요, 정말 눈이 휘둥그레지는 곳이랍니다. \\n이불 떠나서 전 이곳에서 매번 길을 잃거든요.\\n제가 좀 덜 혼란스러울 때 상세히 설명한 편지를 부칠까 해요. 그 편지엔 제 수업에 대한 것들도 들어갈 거고요.\\n수업은 월욜 아침까진 시작하지 않아요, 그런데 오늘이 토욜 밤인 건 함정~\\n하지만 익숙해지고 싶어서 편지를 쓰고 싶지 뭐예요. \\n알지도 못하는 사람에게 편지를 쓰자니 기분이 묘한 것 같아요.\\n아니 그냥 편지 쓰는 것 자체가 제겐 야릿하거든요. 하긴 지금껏 편지라곤 세 통 내지는 네 통 정도 써본 게 다이니까요. \\n그러니 지금 보내드리는 편지가 편지의 기본 형식을 취하지 못했더라도 너그러이 이해봐레요~\\n어제 아침 떠나오기 전, 리펫 원장님과 전 참 심각한 대화를 나누었답니다.\\n원장님께선 앞으로 남은 제 생애 동안 어떻게 행동해야할지를 말씀하셨죠, 누누이 말하듯, 제게 이토록 친절을 베풀고 계시는 그 신사 분(키다리 아저씨)께 특별히 유의하라면서요.\\n그래서 전 편지를 쓰면서도 아주 공손해지려고 주의하고 있어요.\\n하지만 존 스미스 씨(키다리 아저씨의 가명)라 불리길 원하시는 분(즉 가명으로 불리길 원하시는 분)께 공손해봐야 얼마만큼이나 공손해질까요?\\n매력이라곤 하나도 묻어나지 않는 그런 이름(존 스미스)밖엔 고를 수 없으셨나요?\\n왜요, 차라리 ‘말뚝’(노새의 끈을 매다는 말뚝을 의미함) 씨나 아님 ‘옷걸이’ 씨라고 하지 그러셨어요.\\n요번 여름엔 당신에 대해 엄청 생각했었어요. 오랜만에 제게 관심을 표하신 분이시기도 하고, 제가 가족 같은 그런 느낌을 받은 분이시라서요.\\n마치 누군가에게 속한 느낌이랄까, 아주 편안한 느낌이에요.\\n하지만, 뭐, 아저씨를 생각하면 할수록, 제 상상력이 영 힘을 발휘 못하네요.\\n일단 제가 지금까지 알아낸 사실 3가지가 있어요. 물론 당신에 대해서요.\\nⅠ, 키가 크다.\\nⅡ, 부자다. \\nⅢ, 여자애들을 싫어하신다.\\n제 생각에 제가 당신을 ‘여자애를 싫어하는 미스터’라고 불러도 될 거 같은데.\\n그게 만약 모욕적으로 들리신다면, 부자 나리, 이것도 좀 무례하게 들리네요, 마치 돈이 전부인양 느껴질 수 있으니까.\\n하긴 부자다 아니 다는 극히 외적인 가치죠.\\n아마 당신도 계속 부자는 아닐 거 아녀요. \\n월스트리트(세계 금융시장의 중심가)에선 하루에도 수많은 똑똑한 젊은이들이 파산을 신고한다던데요.\\n하지만 뭐 당신은 앞으로도 계속 키가 커실 거잖아요!\\n그래서 전 당신을 키다리 아저씨라 부르기로 결심했답니다. \\n그렇게 불러도 되죠?\\n제가 아저씨의 별명을 지운 건 우리끼리의 비밀이에요… 절대 리펫 원장님껜 말하면 안 되요.\\n2분만 더 있음 밤 10시를 알리는 종이 울릴 거랍니다. \\n저희의 하루일과는 종이 결정하거든요.\\n종이 울리면 밥을 먹고, 종이 울리면 잠을 자고, 종소리와 함께 공부를 시작하죠.\\n나름 활기를 불어넣는다고 할까ㅋㅋ.\\n하긴 뭐 하루 온종일 소방차를 끄는 말이 된 느낌이기도해요. :)\\n(갑자기 종이 울리자) 거봐요 종이 울리네요! 어 불 꺼졌다. 그럼 안뇽.\\n참 학교규정 한번 잘 따르는 학생이라 생각했죠? ㅋㅋ 이게 다 〈존 그리어 고아원〉(여주인공이 나온 고아원이름)에서 몸에 밴 습관 때문이에요.\\n\\n당신을 너무도 존경하는,\\n제루샤 에벗(여주인공이름)이.\\n\\n(2장 끝. 즉 여주인공이 키다리 아저씨에게 1번째로 보낸 편지의 전체 끝)', metadata={'source': './files/키다리아저씨2장.txt'})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='진 웹스터 소설\\n\\n『키다리 아저씨』 우리말 옮김\\n\\n당신\\n\\n키다리 아저씨께\\n\\n키다리 아저씨\\n\\n1장. “짱 나는 수요일”\\n\\n(원문→“우울한 수요일”)\\n\\n매월 첫 번째 수요일은 너무도 끔직한 날이었다. 두려움 가득 그날을 기다렸다가 급히 서둘며 용기와 망각(잊음)으로 견디는 그런 날 말이다. 모든 바닥은 먼지 하나 없이 닦여져야 하고, 모든 의자엔 낙서 하나 없어야 했고, 모든 침대엔 구김 한 번 없어야 했다. 꿈틀대는 97명의 어린 고아들이 때밀이로 박박 때를 밀고 빗질을 하고 다름 질을 한 새 옷에 단추를 단단히 잠겨야했다. 또한 이 97명의 아이들은 예법들을 기억해야했고 만약 평의원(=고아원을 금전적으로 지원하는 분들)님들이 물으실 경우, “네, 선생님.” 또는, “아니오, 선생님.” 라고 대답해야했다. 고통스런 시간이었다. 특히나 고아들 중 가장 나이가 많은, 가련한 ‘제루샤 에벗’(여주인공이름. 에벗은 남자이름임)에게 있어서 그 시간은 자신이 모든 짐을 짊어져야하는 그런 시간이었다. 이전의 것과 마찬가지로, 이 특별했던 첫 번째 수요일도 마침내 꾸억꾸억 종료를 향해 나아가고 있었다. 고아원 손님들을 위해 샌드위치들을 다 만든 후 식료품저장실을 벗어나, 제루샤(여주인공 이름)는 자신의 정규 일을 마무리 짓기 위해 위층으로 향했다. 특히나 ‘바’(원문→에프) 방에 무척 신경을 기울였는데, 그 방에는 4잘부터 7살에 이르는 11명의 어린 꼬마들이 일렬로 널어진 11개의 간이침대에 거주하고 있는 방이었다. 제루샤는 아이들을 모은 다음, 구겨진 옷들을 곱게 펴주고 코를 닦아준 다음 그들이 질서 있게 줄을 이루며 식당으로 출발하도록 했다. 그 애들에게, 빵과 우유 그리고 자두 푸딩(서양과자)과 함께 축복받은 30분을 약속해주고 있는 식당 말이다. 그런 다음 제루샤(여주인공이름)는 창가 쪽 의자 위에 앉아 고동치는 관자놀이(귀와 눈 사이에, 오목하게 들어간 곳)를 차가운 창문에 기대었다. 이날 아침 5시부터 한시도 앉지 못했더랬다. 사람들이 시키는 일을 하느라, 신경질적인 보모가 꾸짖고 다그치는 통에 말이다. 리펫 원장은, 평의원(=이사)들과 부인 방문객들과 얼굴을 마주하며 차분하고 위엄 있게 행동했지만 무대 뒤에선 항상 그런 건 아니었기 때문이다. 제루샤는, 고아원 경계 자국을 내고 있는 키 큰 철제 울타리 너머로, 넓게 뻗은 언 잔디밭 저쪽을 바라다보았다. 그 아래로는 시골의 사유지들이 섞인 울퉁불퉁한 산등성이들이 보였다. 마을의 뾰족탑들이 듬성한 나무들 가운데로 높게 솟아나 있었다. 어쨌든 그날은… 아주 성공적으로 끝이 났다. 적어도 제루샤(여주인공이름)가 아는 한은 말이다. 평의원 분들과 함께 방문한 후원인 분들은 한 바퀴 둘러본 후 제출된 보고서들을 읽고 차(마시는 차)를 한 잔씩 했다. 그리고 이젠 그들도 서둘러 자신들을 기다리는 활기찬 벽난로 가가 있는 집으로 돌아들 가고 있는 중이었다. 다음 달에 있을 그들의 방문이 어떤 성가심을 주는지 망각한 채 말이다. 제루샤는 호기심 가득 그들을 쳐다보며 몸을 숙이고 있었다… 동경의 눈, 횃불… 고아원 정문을 굴러나가고 있는 마차들과 자동차들의 행렬들. 상상 속에서, 제루샤는 첫 번째 마차를 따라 산중턱에 있던 어느 큰 저택으로 향했다.\\n\\n자신이 마차 좌석에 몸을 파묻고는 무심한 듯 “그만 집으로”라고 마부에게 중얼거리고 있는, 모피 코트와 깃털로 테두리를 다듬은 벨벳 모자를 한 자신의 모습을 그려보았다. 하지만 그 큰 집 문지방에 막 다다랐을 때 형상(그림)이 점점 흐려졌다. 제류샤는 상상력을 가졌다… 풍부한 상상력, 그래서인지 리렛 원장은 제루샤에게 말하길, “주의하지 않음 곤란에 부딪힐 거”라고…, 하지만 그 예리한 상상력에도 불구하고, 도무지 그 귀부인 들어설 저택의 현관문 너머는 상상이 잘 안 되었다. 불쌍하고, 열성적이고, 모험적인 고아 제루샤는, 이제 17살이었다. 그녀는 결코 평범한 집에 발을 들여놓아본 적이 없었다. 그래서 도무지 다른 인류, 그러니까 고아원과는 전혀 일면식이 없는 다른 인류가 어떤 일상의 생활을 영위하는지 상상을 해볼 수 없었던 것이다.\\n\\n(▼아래는 고아원 합창단 소년이 장난으로 노래 부르는 소리) 〈제―루―샤  에―벗 부른다 원―장 실에서 내 생각엔 서두르는 게 좋을 듯!〉\\n\\n토미 딜런(이름 알 필요 없음. 한 번만 나오는 이름임)은 합창단에 속해 있었는데, 계단을 올라와 복도를 따라 거닐면서 노래를 부르고 있었다. ‘바’ 방이 가까워짐에 따라 노래는 점점 더 커지고 있었따. 제루샤가 창문에서 머리를 떼어 다시 현실 속 문제들로 돌아와, “누가 찾는데?”라며 걱정을 한 가득 담아, 토미의 노래에 끼어들었다.\\n\\n(▼토미가 노래로 대답하는 것임) 〈리펫 원장이 급히 찾아, 원장실에서, 내 생각에 그녀가 미친 것 같아. 아―아―멘!〉\\n\\n토미(고아원 합창단 단원. 이름 알 필요 없음. 다시 안 나오는 이름임)가 비록 기도문 식으로 노래를 불렀지만, 하지만 그의 말투에 전혀 악의적인 기색은 찾을 수 없었다. 왜냐면 죄를 범한 누이가 화를 내고 있는 여간수(원장)에게 사무실로 호출 당하면 아무리 기가 센 고아원생이라도 동정심을 느끼게 마련인데 그렇지 않았고, 또한 제루샤가 토미의 팔을 홱 잡아당기거나 콧물을 너무 세게 문질러 없애긴 했지만, 그럼에도 불구하고 토미는 제루샤를 좋아했기 때문이다. 제루샤는 잠자코 향했다. 하지만 이마엔 벌써 두 줄이 생긴 상태였다. ‘뭐가 잘못된 걸까’, 하고 제루샤는 생각했다. ‘오늘 나온 샌드위치가 충분히 두덮지 못해서일까? 아님 땅콩 케이크에 땅콩 껍질이라도 들어간 걸까? 아님 틈(구멍)에 끼어 여자 방문객 한 분의 스타킹에 구멍이라도 난 걸까? 그게 아니라면… 아 설마!… 우리 ’바‘ 방에 있는 천사 아가들 중 한 명이 평의원 한 분께 말대꾸를 했나?” 길고 낮은 복도엔 불도 켜져 있지 않았다. 제루샤가 아래로 내려와 보니, 마지막 남은 평의원 한 분이 출발지점에 서 계시다가 열린 문을 통해 ‘포르트 코셰르’(현관 앞의 마차 대는 곳. 사진링크 ▶ http://me2.do/FLzLgF75 )로 걸어가고 계셨다. 제루샤는 흡사 그 남성의 첫인상이 키가 엄청 커다는 인상을 받았더랬다. 커브길에서 자신을 기다리고 있는 자동차를 향해 그 남성이 손을 흔들었다. 자동차가 갑자기 움직이면서 정면에서 접근함에 따라, 눈부신 헤드라이트(자동차의 불빛)가 그 분의 그림자를 벽 안쪽으로 날카롭게(원문→뚜렷이) 내던졌다. 이상하리만치 길게 늘어진 다리들과 팔들이 바닥을 따라 복도의 벽 천정까지 길게 그림자를 그리웠다. 어쩜 세상에, 저건 꼭 무지막지하게 큰 ‘장님거미’(=거미의 일종=키다리 아저씨. 키다리 아저씨의 원래 영어 제목이 ‘장님거미’임. 우리말로 하면 ‘다리가 긴 꺽다리’란 뜻임) 한 마리가 꿈틀대고 있는 것 같잖아. 자동차 헤드라이트에 눈살을 찌푸리다 급 웃음꽃이 핀 제루샤는 원래가 해맑은 영혼이었다. 그래서 전혀 웃기지 않은 상황 속에서도 웃음꽃을 피울 수 있었던 것이다. 평의원의 답답한 이미지에서 일종의 재미를 찾은 건 기대치 않은 소득이었다. 이 사소한 에피소드(사건)에 무척 기분이 좋아진 제루샤는 원장실로 계속 가, 미소 짓는 얼굴로 리펫 원장(이름 몰라도 됨. 다시 안 나옴) 앞에 나타났다. 그런데 얼씨구, 이 나이 지긋한 원장님 또한 정확히 말해 미소는 아니었지만 나름 상냥한 태도로 제루샤를 맞아주었는데, 손님을 맞이하기 위해 입었던 옷만큼이나 다채로운 표정을 짓고 계셨다. “제루샤, 앉거라, 네게 해줄 말이 하나 있다.” 제루샤는 가장 가까이에 있던 의자에 움츠리듯 주저앉아 숨죽인 채 기다렸다. 좀 전 그 자동차의 불빛이 원장실의 창문을 빠르게 훑고 지나갔다. 리펫 원장이 그것을 뒤따라 흘낏 보았다.\\n\\n(리펫 원장의 대사→) “너도, 방금 막 나가신 신사 분을 목격했겠지?” (제루샤의 대사→) “등만 본 걸요.” “그는 우리 평의원들 중에서도 가장 재력과 사회적 영향력을 갖춘 사람이란다, 지금까지 상당한 액수의 금액을 고아원 기금으로 기부도 하셨고 말이다. 엄밀히 말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의 조건으로 내거셨거든.” 이 부분에서 제루샤의 눈이 살짝 휘둥그레졌다. 별난 평의원에 관해 얘기하려 자신을 원장실로 부르는 건 원장의 평소 행동이 아니었기 때문이다. “이 신사 분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리 벤톤’과 ‘헨리 프리즈’ 말이다. (두 소년 모두 몰라도 되는 이름임. 다시 안 나옴) 그 애들은 미스터… 이 평의원께서 후원해 주셨고, 그 애들도 열심히 노력한 결과 나름 성공할 수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두 소년들만 초점이 맞추어져 있었단다. 고아원에 있는 여자애들에겐 전혀 관심을 표하시지 않으셨지. 여자애들이 후원을 받을만한가는 둘째치고서라도 말이다. 그래 내가 네(제루샤)게 말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.” “네, 원장님.”라며 제루샤가 옹알거렸다. 이 부분에서 자신에게 뭔가 대답을 요구하는 것 같았기 때문이다. “오늘 정기 모임에서는, 네(여주인공인 제루샤) 장래에 관한 얘기가 꺼내어졌다.” 리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에 얘기를 천천히 다시 시작했다. “너도 알다시피, 대개의 경우에는, 16살이 되면(제루샤는 현재 17살임) 여기에 계속 있을 수 없다. 하지만 넌 예외였다. 네가 14살에 고아원 학교를 마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건 아니었다만. 결국 내 주장에 따라 넌 근처 마을에 있는 고등학교에 여기에 있으면서 다니는 게 허락되었고, 이제 그 마저도 다 끝마쳤다. 물론 그 이상의 교육(대학교)을 고아원에서 지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱 말이다.” 지난 2년 동안 제루샤가 열심히 생활했다는 사실과 고아원의 편의를 받아 첫 번째 학업 과정과 두 번째 학원 과정을 마친 사실과 아이들을 돌보며 고아원에 머물고 있는 현재의 사정을, 리펫 원장은 쭉 훑어나갔다. “이미 말한 대로, 평의원 회의에서 네 장래에 대한 안건이 상정되어 네 경력이 화제로 다루어졌단다… 아주 철저히 말이다.” 리펫(여자이름) 원장은 독(항아리) 안에 든 이 죄수의 유무죄를 따지려는 듯 비난하는 눈초리로 찬찬히 살폈다. 그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의 성적표에서 유달리 참담했던 과목의 성적을 기억해냈기 때문은 아니었다. “물론 네게 줄 수 있는 배려들 중 하나는 네가 일을 시작할 수 있는 알맞은 직책을 찾아주는 것일 수도 있다.\\n\\n하지만 네 학업성적들 중 어학관련 성적들이 워낙에 우수해서 말이다. 특히나 국어(영어) 성적이 놀랍더구나. 오늘 방문한 위원 중 한 분인 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴)는 학교 이사시기도 한데, 그녀가 말하길 네(여주인공인 제루샤) 수사학(언어의 사용을 연구하는 학문) 선생님과 얘기를 나눠보았는데 선생님이 너에 대해 호평을 하셨다고 하더라. 그리곤 프리처드 여사가 위원회에서, 네(여주인공인 제루샤)가 「짱 나는 수요일」(원문→우울한 수요일)이라고 제목 붙인 에세이 한 편도 소리 내 읽으셨단다.” 그 말에 제루샤(여주인공이름)의 얼굴이 붉어졌다. “그건(짱 나는 수요일이란 에세이. 고아원에 평의원들이 방문하는 날이 매월 첫 번째 수요일이라 에세이 제목에 수요일이 들어감) 네게 은덕을 베푼 시설(고아원)을 조롱하면서도 고마움은 거의 비취지 않는 글 같았다만. 그런 글에 과연 위원회에서 읽혀질 만큼 가치가 있을지 의문이었다만. 어쨌든 네(제루샤. 여주인공이름)겐 다행스럽게도, 그 자리에 계셨던, 미스터… 방금 나가셨던 그 신사 분께선… 음 그 분은 좀 무분별한 유머 감각을 가진 듯 하더구나. 그 건방진 에세이 한 편과 네 국어성적에 힘입어, 그분이 너를 대학교 보내주시겠다고 제안했단다.” “대학에요?”라며 눈이 휘둥그레져선 제루샤(여주인공이름)가 말했다. 리펫 원장이 고개를 끄덕였다. “그(키다리 아저씨)는 그 문제를 나와 상의하러 마지막까지 남아 있었던 것이다. 원래가 평의원 분들은 유별난 데가 많은데, 굳이 말하자면, 그 신사 분은 좀 상식을 벗어난 별난 데가 있다. 그 분은 네(여주인공) 창의력을 믿는다더구나. 그래서 네게 작가가 될 수 있는 교육을 받게 해줄 계획이라더라.” “작가요?” 어찌나 정신이 얼얼한지 제루샤는 다만 리펫 원장의 마지막 단어(작가)를 반복하기만 했다. (리펫 원장의 대사→) ”그것이 그(키다리 아저씨)의 희망이다. 그래서 어찌될 지는 곧 알게 되겠지. 일단 그 분은 네게 제법 넉넉한 용돈을 주실 게다, 거의, 용돈이라곤 생전 한 번 받아 본 적이 없는 여자애에게 있어선 아주 넉넉한 금액일 게다. 하지만 (읽기 쉽게 문단을 여러 번 나눔. 모두 원장님의 긴 대사임) 세부적인 사항은 그 분이 짜주실 게다, 난 일일이 제안을 하고 싶지 않더라만. 넌 일단 여름 동안은 여기(고아원) 머물러야 한다. 그리고 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴. 학교의 이사)께서 네 채비(여행준비)를 관리해주시기로 친절하게도 제안하셨단다. 네 식대(식사비용)와 수업료는 대학교로 바로 지불이 될 거다, 넌 거기에 머무는 4년 동안 추가적으로 매달 70만원(원문→35달러. 이해가 쉽도록 70만원으로 해석했음. 전혀 근거가 없는 계산법임^^)을 용돈으로 받게 될 거다. 그 정도 용돈이면 네가 한 점 부끄러움 없이 다른 학생들과 동등하게 생활할 수 있을 게다. 용돈은 매달 한 번씩 그 신사 분(키다리 아저씨)의 개인 비서를 통해 네게 보내어질 게다. 넌 그 답례로 그분께 매달 한 차례 답례 편지를 써야 한다.\\n\\n그건(답례편지)… 용돈을 주시는 것에 대한 감사 편지여서는 안 된다. 그 분은 그런 식의 언급을 극도로 싫어하시는 분이시니까. 하지만 넌 편지에서 네 학업의 진도와 네 매일 매일의 일상들의 세부사항들을 그 분께 말씀드려야 한다. 만약 네 부모님들께서 살아계셨다면 네가 적어 보냈을 그런 안부 편지를 넌 그분께 편지로 보내면 되는 거야.” (←큰 따옴표 끝. 리펫 원장의 대사 끝) (리펫 원장의 대사 계속→) “네가 쓴 편지들은 존 스미스 씨 앞으로 비서(키다리 아저씨의 개인비서)를 통해 안전하게 전달될 거다. 물론 널 돕기로 한 그 분의 성함이 존 스미스란 얘기를 아니다. 어쨌든 그 분은 자신이 드러나는 걸 꺼리시니까. 너(여주인공)에게 그 분은 그냥 존 스미스란 얘기일 뿐이다. 굳이 그 분이 네게서 편지를 요구하시는 건, 그 분이 생각하기에 문학적 표현을 기르는데 손 편지만한 게 없다 여기시기 때문이다. 또한 그 분은 네가 나아가는 바를 그때그때 알기를 바라신다. 물론 그 분이 네 편지에 답하시는 일을 결코 없을 게다. 또한 네 편지엔 그것에 대해 어떤 사소한 언급도 있어선 아니 된다. 그 분은 손 편지 쓰는 걸 극히 싫어하신다. 그러니 넌 그 분께 부담을 안겨선 안 돼. 만약 네가 퇴학을 당하는 경우와 같은 그런 어쩔 수 없는 상황이 벌어져 답장이 꼭 필요할 것 같으면, 물론 그런 일이 없어야겠지만, 넌 ‘그리그스’(영어단어 ‘그리그’는 쾌활한 사람이란 뜻임. 귀뚜라미란 뜻도 있음) 씨와 연락을 취할 수도 있을 게다. 물론 그리그스 씨는 그 분의 개인비서다. 매월 부쳐야하는 이 편지는 네 입장에선 절대적으로 준수해야하는 의무다. 스미스 씨(키다리 아저씨의 가명)가 요구하는 유일한 보상이니, 넌 그 편지들을 네가 지불하는 계산서인양 꼼꼼히 보내야한다. 내 생각이다만, 편지는 항상 예의발라야 되겠고 네 학업의 성과들이 반영되어야 되겠지. 우선은 〈존 그리어 고아원〉(←고아원이름임)의 평의원 한 분께 공손히 편지를 보내야한다는 것만 기억하고 있거라.” (←큰 따옴표 끝. 리펫 원장의 대사 끝) 제루샤의 두 눈은 오랫동안 문만 바라보고 있었다. 그녀의 머릿속엔 지금 흥분의 수레바퀴가 돌고 있어 리펫 원장의 상투적인 말투로부터 벗어나기만을 바랐을 뿐이기 때문이다. 제루샤가 시험 삼아 자리에서 일어나 한발작 뒷걸음을 쳐보았다. 그러자 리펫 원장이 손짓으로 “좀 더 기다리라”고 말했다. 그건 리펫 원장의 일장연설이 한 차례 더 있을 예정임을 의미했다. “네게 온 이 지극히 드문 행운에 대해 네가 적절히 감사할 줄 안다고 내가 믿어도 되겠지? 도대체 이런 흔치 않은 기회를 거머쥔 여자 아이가 이 세상에 일찍이 너 말고 누가 또 있었겠니? 그러니 넌 이 점을 분명히 기억하고서 앞으로 행동을…” “전(=저는)… 아, 네, 감사합니다, 원장님. 방금 생각난 건데, 제가 지금 ‘프레디 퍼킨즈’(고아 이름.\\n\\n다시 안 나오는 이름임)의 바지에 헝겊을 깁다 온 걸 깜빡해서요.” 문이 뒤에서 “꽝!”하고 닫히자, 리펫 원장은 장황한(=긴) 연설을 하다 말고 아래턱을 쭉 내린 상태로 문을 바라보았다.\\n\\n(1장 끝)\\n\\n(여기까지가 1장 끝입니다. 2장부터는 한 달에 한 번씩 키다리 아저씨에게 보낸 편지들입니다. 이후, 1장, 2장과 같이 ‘장’은 제가 붙인 거고 원문엔 ‘장’의 구분이 없습니다.)\\n\\n2장. 키다리 아저씨\\n\\n(옮긴이 설명 1 : 읽기 쉽게, 여주인공이 한 달에 한 번씩 키다리 아저씨에게 보낸 편지마다 새로운 ‘장’을 붙이겠습니다. 2장, 3장,...30장 이런 식으로요~ 2장=첫 번째 편지. 3장-두 번째 편지.... 30장=29번째로 보낸 편지) (옮긴이 설명 2 : 이제부터는 편지입니다. 헷갈릴 수 있는데 소설이 편지의 형식입니다. 서점에 가셨을 때 키다리 아저씨 번역서를 한 번 훑어보시면 소설의 이해가 빠릅니다. 말이 편지 형식이지 인터넷으로 처음 접하면 뭔지 모를 수가 있거든요.)\\n\\n제루샤 에벗 양이\\n\\n키다리 아저씨인 스미스 씨에게\\n\\n보낸 편지들\\n\\n(제가 추가한 제목)\\n\\n2장. 대학교 1학년 (17세)\\n\\n(본문 시작) 퍼거슨 강당 215호에서 9월 24일 (여주인공 17세. 대학교 1학년)\\n\\n고아들을 대학에 보내주시는 고마운 평의원(=키다리 아저씨) 분께,\\n\\n캭, 저 왔어요! 어제 열차로 자그마치 4시간 동안을 여행했답니다. 어찌나 묘한 감동이던 지요, 전엔 한 번도 기차를 타본 적이 없었걸랑요. 대학교(대학원을 두지 않고 대학교의 학부만 있는 대학교)는 엄청 커요, 정말 눈이 휘둥그레지는 곳이랍니다. 이불 떠나서 전 이곳에서 매번 길을 잃거든요. 제가 좀 덜 혼란스러울 때 상세히 설명한 편지를 부칠까 해요. 그 편지엔 제 수업에 대한 것들도 들어갈 거고요. 수업은 월욜 아침까진 시작하지 않아요, 그런데 오늘이 토욜 밤인 건 함정~ 하지만 익숙해지고 싶어서 편지를 쓰고 싶지 뭐예요. 알지도 못하는 사람에게 편지를 쓰자니 기분이 묘한 것 같아요. 아니 그냥 편지 쓰는 것 자체가 제겐 야릿하거든요. 하긴 지금껏 편지라곤 세 통 내지는 네 통 정도 써본 게 다이니까요. 그러니 지금 보내드리는 편지가 편지의 기본 형식을 취하지 못했더라도 너그러이 이해봐레요~ 어제 아침 떠나오기 전, 리펫 원장님과 전 참 심각한 대화를 나누었답니다. 원장님께선 앞으로 남은 제 생애 동안 어떻게 행동해야할지를 말씀하셨죠, 누누이 말하듯, 제게 이토록 친절을 베풀고 계시는 그 신사 분(키다리 아저씨)께 특별히 유의하라면서요. 그래서 전 편지를 쓰면서도 아주 공손해지려고 주의하고 있어요. 하지만 존 스미스 씨(키다리 아저씨의 가명)라 불리길 원하시는 분(즉 가명으로 불리길 원하시는 분)께 공손해봐야 얼마만큼이나 공손해질까요? 매력이라곤 하나도 묻어나지 않는 그런 이름(존 스미스)밖엔 고를 수 없으셨나요? 왜요, 차라리 ‘말뚝’(노새의 끈을 매다는 말뚝을 의미함) 씨나 아님 ‘옷걸이’ 씨라고 하지 그러셨어요. 요번 여름엔 당신에 대해 엄청 생각했었어요. 오랜만에 제게 관심을 표하신 분이시기도 하고, 제가 가족 같은 그런 느낌을 받은 분이시라서요. 마치 누군가에게 속한 느낌이랄까, 아주 편안한 느낌이에요. 하지만, 뭐, 아저씨를 생각하면 할수록, 제 상상력이 영 힘을 발휘 못하네요. 일단 제가 지금까지 알아낸 사실 3가지가 있어요. 물론 당신에 대해서요. Ⅰ, 키가 크다. Ⅱ, 부자다. Ⅲ, 여자애들을 싫어하신다. 제 생각에 제가 당신을 ‘여자애를 싫어하는 미스터’라고 불러도 될 거 같은데. 그게 만약 모욕적으로 들리신다면, 부자 나리, 이것도 좀 무례하게 들리네요, 마치 돈이 전부인양 느껴질 수 있으니까. 하긴 부자다 아니 다는 극히 외적인 가치죠. 아마 당신도 계속 부자는 아닐 거 아녀요. 월스트리트(세계 금융시장의 중심가)에선 하루에도 수많은 똑똑한 젊은이들이 파산을 신고한다던데요. 하지만 뭐 당신은 앞으로도 계속 키가 커실 거잖아요! 그래서 전 당신을 키다리 아저씨라 부르기로 결심했답니다. 그렇게 불러도 되죠? 제가 아저씨의 별명을 지운 건 우리끼리의 비밀이에요… 절대 리펫 원장님껜 말하면 안 되요. 2분만 더 있음 밤 10시를 알리는 종이 울릴 거랍니다. 저희의 하루일과는 종이 결정하거든요. 종이 울리면 밥을 먹고, 종이 울리면 잠을 자고, 종소리와 함께 공부를 시작하죠. 나름 활기를 불어넣는다고 할까ㅋㅋ.\\n\\n하긴 뭐 하루 온종일 소방차를 끄는 말이 된 느낌이기도해요. :) (갑자기 종이 울리자) 거봐요 종이 울리네요! 어 불 꺼졌다. 그럼 안뇽. 참 학교규정 한번 잘 따르는 학생이라 생각했죠? ㅋㅋ 이게 다 〈존 그리어 고아원〉(여주인공이 나온 고아원이름)에서 몸에 밴 습관 때문이에요.\\n\\n당신을 너무도 존경하는,\\n\\n제루샤 에벗(여주인공이름)이.\\n\\n(2장 끝. 즉 여주인공이 키다리 아저씨에게 1번째로 보낸 편지의 전체 끝)', metadata={'source': './files/키다리아저씨2장.txt'})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='진 웹스터 소설\\n\\n『키다리 아저씨』 우리말 옮김\\n\\n당신\\n\\n키다리 아저씨께\\n\\n키다리 아저씨\\n\\n1장. “짱 나는 수요일”\\n\\n(원문→“우울한 수요일”)\\n\\n매월 첫 번째 수요일은 너무도 끔직한 날이었다. 두려움 가득 그날을 기다렸다가 급히 서둘며 용기와 망각(잊음)으로 견디는 그런 날 말이다. 모든 바닥은 먼지 하나 없이 닦여져야 하고, 모든 의자엔 낙서 하나 없어야 했고, 모든 침대엔 구김 한 번 없어야 했다. 꿈틀대는 97명의 어린 고아들이 때밀이로 박박 때를 밀고 빗질을 하고 다름 질을 한 새 옷에 단추를 단단히 잠겨야했다. 또한 이 97명의 아이들은 예법들을 기억해야했고 만약 평의원(=고아원을 금전적으로 지원하는 분들)님들이 물으실 경우, “네, 선생님.” 또는, “아니오, 선생님.” 라고 대답해야했다. 고통스런 시간이었다. 특히나 고아들 중 가장 나이가 많은, 가련한 ‘제루샤 에벗’(여주인공이름. 에벗은 남자이름임)에게 있어서 그 시간은 자신이 모든 짐을 짊어져야하는 그런 시간이었다. 이전의 것과 마찬가지로, 이 특별했던 첫 번째 수요일도 마침내 꾸억꾸억 종료를 향해 나아가고 있었다. 고아원 손님들을 위해 샌드위치들을 다 만든 후 식료품저장실을 벗어나, 제루샤(여주인공 이름)는 자신의 정규 일을 마무리 짓기 위해 위층으로 향했다. 특히나 ‘바’(원문→에프) 방에 무척 신경을 기울였는데, 그 방에는 4잘부터 7살에 이르는 11명의 어린 꼬마들이 일렬로 널어진 11개의 간이침대에 거주하고 있는 방이었다. 제루샤는 아이들을 모은 다음, 구겨진 옷들을 곱게 펴주고 코를 닦아준 다음 그들이 질서 있게 줄을 이루며 식당으로 출발하도록 했다. 그 애들에게, 빵과 우유 그리고 자두 푸딩(서양과자)과 함께 축복받은 30분을 약속해주고 있는 식당 말이다. 그런 다음 제루샤(여주인공이름)는 창가 쪽 의자 위에 앉아 고동치는 관자놀이(귀와 눈 사이에, 오목하게 들어간 곳)를 차가운 창문에 기대었다. 이날 아침 5시부터 한시도 앉지 못했더랬다. 사람들이 시키는 일을 하느라, 신경질적인 보모가 꾸짖고 다그치는 통에 말이다. 리펫 원장은, 평의원(=이사)들과 부인 방문객들과 얼굴을 마주하며 차분하고 위엄 있게 행동했지만 무대 뒤에선 항상 그런 건 아니었기 때문이다. 제루샤는, 고아원 경계 자국을 내고 있는 키 큰 철제 울타리 너머로, 넓게 뻗은 언 잔디밭 저쪽을 바라다보았다. 그 아래로는 시골의 사유지들이 섞인 울퉁불퉁한 산등성이들이 보였다. 마을의 뾰족탑들이 듬성한 나무들 가운데로 높게 솟아나 있었다. 어쨌든 그날은… 아주 성공적으로 끝이 났다. 적어도 제루샤(여주인공이름)가 아는 한은 말이다. 평의원 분들과 함께 방문한 후원인 분들은 한 바퀴 둘러본 후 제출된 보고서들을 읽고 차(마시는 차)를 한 잔씩 했다. 그리고 이젠 그들도 서둘러 자신들을 기다리는 활기찬 벽난로 가가 있는 집으로 돌아들 가고 있는 중이었다. 다음 달에 있을 그들의 방문이 어떤 성가심을 주는지 망각한 채 말이다. 제루샤는 호기심 가득 그들을 쳐다보며 몸을 숙이고 있었다… 동경의 눈, 횃불… 고아원 정문을 굴러나가고 있는 마차들과 자동차들의 행렬들. 상상 속에서, 제루샤는 첫 번째 마차를 따라 산중턱에 있던 어느 큰 저택으로 향했다.\\n\\n자신이 마차 좌석에 몸을 파묻고는 무심한 듯 “그만 집으로”라고 마부에게 중얼거리고 있는, 모피 코트와 깃털로 테두리를 다듬은 벨벳 모자를 한 자신의 모습을 그려보았다. 하지만 그 큰 집 문지방에 막 다다랐을 때 형상(그림)이 점점 흐려졌다. 제류샤는 상상력을 가졌다… 풍부한 상상력, 그래서인지 리렛 원장은 제루샤에게 말하길, “주의하지 않음 곤란에 부딪힐 거”라고…, 하지만 그 예리한 상상력에도 불구하고, 도무지 그 귀부인 들어설 저택의 현관문 너머는 상상이 잘 안 되었다. 불쌍하고, 열성적이고, 모험적인 고아 제루샤는, 이제 17살이었다. 그녀는 결코 평범한 집에 발을 들여놓아본 적이 없었다. 그래서 도무지 다른 인류, 그러니까 고아원과는 전혀 일면식이 없는 다른 인류가 어떤 일상의 생활을 영위하는지 상상을 해볼 수 없었던 것이다.\\n\\n(▼아래는 고아원 합창단 소년이 장난으로 노래 부르는 소리) 〈제―루―샤  에―벗 부른다 원―장 실에서 내 생각엔 서두르는 게 좋을 듯!〉\\n\\n토미 딜런(이름 알 필요 없음. 한 번만 나오는 이름임)은 합창단에 속해 있었는데, 계단을 올라와 복도를 따라 거닐면서 노래를 부르고 있었다. ‘바’ 방이 가까워짐에 따라 노래는 점점 더 커지고 있었따. 제루샤가 창문에서 머리를 떼어 다시 현실 속 문제들로 돌아와, “누가 찾는데?”라며 걱정을 한 가득 담아, 토미의 노래에 끼어들었다.\\n\\n(▼토미가 노래로 대답하는 것임) 〈리펫 원장이 급히 찾아, 원장실에서, 내 생각에 그녀가 미친 것 같아. 아―아―멘!〉\\n\\n토미(고아원 합창단 단원. 이름 알 필요 없음. 다시 안 나오는 이름임)가 비록 기도문 식으로 노래를 불렀지만, 하지만 그의 말투에 전혀 악의적인 기색은 찾을 수 없었다. 왜냐면 죄를 범한 누이가 화를 내고 있는 여간수(원장)에게 사무실로 호출 당하면 아무리 기가 센 고아원생이라도 동정심을 느끼게 마련인데 그렇지 않았고, 또한 제루샤가 토미의 팔을 홱 잡아당기거나 콧물을 너무 세게 문질러 없애긴 했지만, 그럼에도 불구하고 토미는 제루샤를 좋아했기 때문이다. 제루샤는 잠자코 향했다. 하지만 이마엔 벌써 두 줄이 생긴 상태였다. ‘뭐가 잘못된 걸까’, 하고 제루샤는 생각했다. ‘오늘 나온 샌드위치가 충분히 두덮지 못해서일까? 아님 땅콩 케이크에 땅콩 껍질이라도 들어간 걸까? 아님 틈(구멍)에 끼어 여자 방문객 한 분의 스타킹에 구멍이라도 난 걸까? 그게 아니라면… 아 설마!… 우리 ’바‘ 방에 있는 천사 아가들 중 한 명이 평의원 한 분께 말대꾸를 했나?” 길고 낮은 복도엔 불도 켜져 있지 않았다. 제루샤가 아래로 내려와 보니, 마지막 남은 평의원 한 분이 출발지점에 서 계시다가 열린 문을 통해 ‘포르트 코셰르’(현관 앞의 마차 대는 곳. 사진링크 ▶ http://me2.do/FLzLgF75 )로 걸어가고 계셨다. 제루샤는 흡사 그 남성의 첫인상이 키가 엄청 커다는 인상을 받았더랬다. 커브길에서 자신을 기다리고 있는 자동차를 향해 그 남성이 손을 흔들었다. 자동차가 갑자기 움직이면서 정면에서 접근함에 따라, 눈부신 헤드라이트(자동차의 불빛)가 그 분의 그림자를 벽 안쪽으로 날카롭게(원문→뚜렷이) 내던졌다. 이상하리만치 길게 늘어진 다리들과 팔들이 바닥을 따라 복도의 벽 천정까지 길게 그림자를 그리웠다. 어쩜 세상에, 저건 꼭 무지막지하게 큰 ‘장님거미’(=거미의 일종=키다리 아저씨. 키다리 아저씨의 원래 영어 제목이 ‘장님거미’임. 우리말로 하면 ‘다리가 긴 꺽다리’란 뜻임) 한 마리가 꿈틀대고 있는 것 같잖아. 자동차 헤드라이트에 눈살을 찌푸리다 급 웃음꽃이 핀 제루샤는 원래가 해맑은 영혼이었다. 그래서 전혀 웃기지 않은 상황 속에서도 웃음꽃을 피울 수 있었던 것이다. 평의원의 답답한 이미지에서 일종의 재미를 찾은 건 기대치 않은 소득이었다. 이 사소한 에피소드(사건)에 무척 기분이 좋아진 제루샤는 원장실로 계속 가, 미소 짓는 얼굴로 리펫 원장(이름 몰라도 됨. 다시 안 나옴) 앞에 나타났다. 그런데 얼씨구, 이 나이 지긋한 원장님 또한 정확히 말해 미소는 아니었지만 나름 상냥한 태도로 제루샤를 맞아주었는데, 손님을 맞이하기 위해 입었던 옷만큼이나 다채로운 표정을 짓고 계셨다. “제루샤, 앉거라, 네게 해줄 말이 하나 있다.” 제루샤는 가장 가까이에 있던 의자에 움츠리듯 주저앉아 숨죽인 채 기다렸다. 좀 전 그 자동차의 불빛이 원장실의 창문을 빠르게 훑고 지나갔다. 리펫 원장이 그것을 뒤따라 흘낏 보았다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='(리펫 원장의 대사→) “너도, 방금 막 나가신 신사 분을 목격했겠지?” (제루샤의 대사→) “등만 본 걸요.” “그는 우리 평의원들 중에서도 가장 재력과 사회적 영향력을 갖춘 사람이란다, 지금까지 상당한 액수의 금액을 고아원 기금으로 기부도 하셨고 말이다. 엄밀히 말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의 조건으로 내거셨거든.” 이 부분에서 제루샤의 눈이 살짝 휘둥그레졌다. 별난 평의원에 관해 얘기하려 자신을 원장실로 부르는 건 원장의 평소 행동이 아니었기 때문이다. “이 신사 분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리 벤톤’과 ‘헨리 프리즈’ 말이다. (두 소년 모두 몰라도 되는 이름임. 다시 안 나옴) 그 애들은 미스터… 이 평의원께서 후원해 주셨고, 그 애들도 열심히 노력한 결과 나름 성공할 수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두 소년들만 초점이 맞추어져 있었단다. 고아원에 있는 여자애들에겐 전혀 관심을 표하시지 않으셨지. 여자애들이 후원을 받을만한가는 둘째치고서라도 말이다. 그래 내가 네(제루샤)게 말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.” “네, 원장님.”라며 제루샤가 옹알거렸다. 이 부분에서 자신에게 뭔가 대답을 요구하는 것 같았기 때문이다. “오늘 정기 모임에서는, 네(여주인공인 제루샤) 장래에 관한 얘기가 꺼내어졌다.” 리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에 얘기를 천천히 다시 시작했다. “너도 알다시피, 대개의 경우에는, 16살이 되면(제루샤는 현재 17살임) 여기에 계속 있을 수 없다. 하지만 넌 예외였다. 네가 14살에 고아원 학교를 마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건 아니었다만. 결국 내 주장에 따라 넌 근처 마을에 있는 고등학교에 여기에 있으면서 다니는 게 허락되었고, 이제 그 마저도 다 끝마쳤다. 물론 그 이상의 교육(대학교)을 고아원에서 지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱 말이다.” 지난 2년 동안 제루샤가 열심히 생활했다는 사실과 고아원의 편의를 받아 첫 번째 학업 과정과 두 번째 학원 과정을 마친 사실과 아이들을 돌보며 고아원에 머물고 있는 현재의 사정을, 리펫 원장은 쭉 훑어나갔다. “이미 말한 대로, 평의원 회의에서 네 장래에 대한 안건이 상정되어 네 경력이 화제로 다루어졌단다… 아주 철저히 말이다.” 리펫(여자이름) 원장은 독(항아리) 안에 든 이 죄수의 유무죄를 따지려는 듯 비난하는 눈초리로 찬찬히 살폈다. 그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의 성적표에서 유달리 참담했던 과목의 성적을 기억해냈기 때문은 아니었다. “물론 네게 줄 수 있는 배려들 중 하나는 네가 일을 시작할 수 있는 알맞은 직책을 찾아주는 것일 수도 있다.\\n\\n하지만 네 학업성적들 중 어학관련 성적들이 워낙에 우수해서 말이다. 특히나 국어(영어) 성적이 놀랍더구나. 오늘 방문한 위원 중 한 분인 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴)는 학교 이사시기도 한데, 그녀가 말하길 네(여주인공인 제루샤) 수사학(언어의 사용을 연구하는 학문) 선생님과 얘기를 나눠보았는데 선생님이 너에 대해 호평을 하셨다고 하더라. 그리곤 프리처드 여사가 위원회에서, 네(여주인공인 제루샤)가 「짱 나는 수요일」(원문→우울한 수요일)이라고 제목 붙인 에세이 한 편도 소리 내 읽으셨단다.” 그 말에 제루샤(여주인공이름)의 얼굴이 붉어졌다. “그건(짱 나는 수요일이란 에세이. 고아원에 평의원들이 방문하는 날이 매월 첫 번째 수요일이라 에세이 제목에 수요일이 들어감) 네게 은덕을 베푼 시설(고아원)을 조롱하면서도 고마움은 거의 비취지 않는 글 같았다만. 그런 글에 과연 위원회에서 읽혀질 만큼 가치가 있을지 의문이었다만. 어쨌든 네(제루샤. 여주인공이름)겐 다행스럽게도, 그 자리에 계셨던, 미스터… 방금 나가셨던 그 신사 분께선… 음 그 분은 좀 무분별한 유머 감각을 가진 듯 하더구나. 그 건방진 에세이 한 편과 네 국어성적에 힘입어, 그분이 너를 대학교 보내주시겠다고 제안했단다.” “대학에요?”라며 눈이 휘둥그레져선 제루샤(여주인공이름)가 말했다. 리펫 원장이 고개를 끄덕였다. “그(키다리 아저씨)는 그 문제를 나와 상의하러 마지막까지 남아 있었던 것이다. 원래가 평의원 분들은 유별난 데가 많은데, 굳이 말하자면, 그 신사 분은 좀 상식을 벗어난 별난 데가 있다. 그 분은 네(여주인공) 창의력을 믿는다더구나. 그래서 네게 작가가 될 수 있는 교육을 받게 해줄 계획이라더라.” “작가요?” 어찌나 정신이 얼얼한지 제루샤는 다만 리펫 원장의 마지막 단어(작가)를 반복하기만 했다. (리펫 원장의 대사→) ”그것이 그(키다리 아저씨)의 희망이다. 그래서 어찌될 지는 곧 알게 되겠지. 일단 그 분은 네게 제법 넉넉한 용돈을 주실 게다, 거의, 용돈이라곤 생전 한 번 받아 본 적이 없는 여자애에게 있어선 아주 넉넉한 금액일 게다. 하지만 (읽기 쉽게 문단을 여러 번 나눔. 모두 원장님의 긴 대사임) 세부적인 사항은 그 분이 짜주실 게다, 난 일일이 제안을 하고 싶지 않더라만. 넌 일단 여름 동안은 여기(고아원) 머물러야 한다. 그리고 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴. 학교의 이사)께서 네 채비(여행준비)를 관리해주시기로 친절하게도 제안하셨단다. 네 식대(식사비용)와 수업료는 대학교로 바로 지불이 될 거다, 넌 거기에 머무는 4년 동안 추가적으로 매달 70만원(원문→35달러. 이해가 쉽도록 70만원으로 해석했음. 전혀 근거가 없는 계산법임^^)을 용돈으로 받게 될 거다. 그 정도 용돈이면 네가 한 점 부끄러움 없이 다른 학생들과 동등하게 생활할 수 있을 게다. 용돈은 매달 한 번씩 그 신사 분(키다리 아저씨)의 개인 비서를 통해 네게 보내어질 게다. 넌 그 답례로 그분께 매달 한 차례 답례 편지를 써야 한다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='그건(답례편지)… 용돈을 주시는 것에 대한 감사 편지여서는 안 된다. 그 분은 그런 식의 언급을 극도로 싫어하시는 분이시니까. 하지만 넌 편지에서 네 학업의 진도와 네 매일 매일의 일상들의 세부사항들을 그 분께 말씀드려야 한다. 만약 네 부모님들께서 살아계셨다면 네가 적어 보냈을 그런 안부 편지를 넌 그분께 편지로 보내면 되는 거야.” (←큰 따옴표 끝. 리펫 원장의 대사 끝) (리펫 원장의 대사 계속→) “네가 쓴 편지들은 존 스미스 씨 앞으로 비서(키다리 아저씨의 개인비서)를 통해 안전하게 전달될 거다. 물론 널 돕기로 한 그 분의 성함이 존 스미스란 얘기를 아니다. 어쨌든 그 분은 자신이 드러나는 걸 꺼리시니까. 너(여주인공)에게 그 분은 그냥 존 스미스란 얘기일 뿐이다. 굳이 그 분이 네게서 편지를 요구하시는 건, 그 분이 생각하기에 문학적 표현을 기르는데 손 편지만한 게 없다 여기시기 때문이다. 또한 그 분은 네가 나아가는 바를 그때그때 알기를 바라신다. 물론 그 분이 네 편지에 답하시는 일을 결코 없을 게다. 또한 네 편지엔 그것에 대해 어떤 사소한 언급도 있어선 아니 된다. 그 분은 손 편지 쓰는 걸 극히 싫어하신다. 그러니 넌 그 분께 부담을 안겨선 안 돼. 만약 네가 퇴학을 당하는 경우와 같은 그런 어쩔 수 없는 상황이 벌어져 답장이 꼭 필요할 것 같으면, 물론 그런 일이 없어야겠지만, 넌 ‘그리그스’(영어단어 ‘그리그’는 쾌활한 사람이란 뜻임. 귀뚜라미란 뜻도 있음) 씨와 연락을 취할 수도 있을 게다. 물론 그리그스 씨는 그 분의 개인비서다. 매월 부쳐야하는 이 편지는 네 입장에선 절대적으로 준수해야하는 의무다. 스미스 씨(키다리 아저씨의 가명)가 요구하는 유일한 보상이니, 넌 그 편지들을 네가 지불하는 계산서인양 꼼꼼히 보내야한다. 내 생각이다만, 편지는 항상 예의발라야 되겠고 네 학업의 성과들이 반영되어야 되겠지. 우선은 〈존 그리어 고아원〉(←고아원이름임)의 평의원 한 분께 공손히 편지를 보내야한다는 것만 기억하고 있거라.” (←큰 따옴표 끝. 리펫 원장의 대사 끝) 제루샤의 두 눈은 오랫동안 문만 바라보고 있었다. 그녀의 머릿속엔 지금 흥분의 수레바퀴가 돌고 있어 리펫 원장의 상투적인 말투로부터 벗어나기만을 바랐을 뿐이기 때문이다. 제루샤가 시험 삼아 자리에서 일어나 한발작 뒷걸음을 쳐보았다. 그러자 리펫 원장이 손짓으로 “좀 더 기다리라”고 말했다. 그건 리펫 원장의 일장연설이 한 차례 더 있을 예정임을 의미했다. “네게 온 이 지극히 드문 행운에 대해 네가 적절히 감사할 줄 안다고 내가 믿어도 되겠지? 도대체 이런 흔치 않은 기회를 거머쥔 여자 아이가 이 세상에 일찍이 너 말고 누가 또 있었겠니? 그러니 넌 이 점을 분명히 기억하고서 앞으로 행동을…” “전(=저는)… 아, 네, 감사합니다, 원장님. 방금 생각난 건데, 제가 지금 ‘프레디 퍼킨즈’(고아 이름.\\n\\n다시 안 나오는 이름임)의 바지에 헝겊을 깁다 온 걸 깜빡해서요.” 문이 뒤에서 “꽝!”하고 닫히자, 리펫 원장은 장황한(=긴) 연설을 하다 말고 아래턱을 쭉 내린 상태로 문을 바라보았다.\\n\\n(1장 끝)\\n\\n(여기까지가 1장 끝입니다. 2장부터는 한 달에 한 번씩 키다리 아저씨에게 보낸 편지들입니다. 이후, 1장, 2장과 같이 ‘장’은 제가 붙인 거고 원문엔 ‘장’의 구분이 없습니다.)\\n\\n2장. 키다리 아저씨\\n\\n(옮긴이 설명 1 : 읽기 쉽게, 여주인공이 한 달에 한 번씩 키다리 아저씨에게 보낸 편지마다 새로운 ‘장’을 붙이겠습니다. 2장, 3장,...30장 이런 식으로요~ 2장=첫 번째 편지. 3장-두 번째 편지.... 30장=29번째로 보낸 편지) (옮긴이 설명 2 : 이제부터는 편지입니다. 헷갈릴 수 있는데 소설이 편지의 형식입니다. 서점에 가셨을 때 키다리 아저씨 번역서를 한 번 훑어보시면 소설의 이해가 빠릅니다. 말이 편지 형식이지 인터넷으로 처음 접하면 뭔지 모를 수가 있거든요.)\\n\\n제루샤 에벗 양이\\n\\n키다리 아저씨인 스미스 씨에게\\n\\n보낸 편지들\\n\\n(제가 추가한 제목)\\n\\n2장. 대학교 1학년 (17세)\\n\\n(본문 시작) 퍼거슨 강당 215호에서 9월 24일 (여주인공 17세. 대학교 1학년)\\n\\n고아들을 대학에 보내주시는 고마운 평의원(=키다리 아저씨) 분께,\\n\\n캭, 저 왔어요! 어제 열차로 자그마치 4시간 동안을 여행했답니다. 어찌나 묘한 감동이던 지요, 전엔 한 번도 기차를 타본 적이 없었걸랑요. 대학교(대학원을 두지 않고 대학교의 학부만 있는 대학교)는 엄청 커요, 정말 눈이 휘둥그레지는 곳이랍니다. 이불 떠나서 전 이곳에서 매번 길을 잃거든요. 제가 좀 덜 혼란스러울 때 상세히 설명한 편지를 부칠까 해요. 그 편지엔 제 수업에 대한 것들도 들어갈 거고요. 수업은 월욜 아침까진 시작하지 않아요, 그런데 오늘이 토욜 밤인 건 함정~ 하지만 익숙해지고 싶어서 편지를 쓰고 싶지 뭐예요. 알지도 못하는 사람에게 편지를 쓰자니 기분이 묘한 것 같아요. 아니 그냥 편지 쓰는 것 자체가 제겐 야릿하거든요. 하긴 지금껏 편지라곤 세 통 내지는 네 통 정도 써본 게 다이니까요. 그러니 지금 보내드리는 편지가 편지의 기본 형식을 취하지 못했더라도 너그러이 이해봐레요~ 어제 아침 떠나오기 전, 리펫 원장님과 전 참 심각한 대화를 나누었답니다. 원장님께선 앞으로 남은 제 생애 동안 어떻게 행동해야할지를 말씀하셨죠, 누누이 말하듯, 제게 이토록 친절을 베풀고 계시는 그 신사 분(키다리 아저씨)께 특별히 유의하라면서요. 그래서 전 편지를 쓰면서도 아주 공손해지려고 주의하고 있어요. 하지만 존 스미스 씨(키다리 아저씨의 가명)라 불리길 원하시는 분(즉 가명으로 불리길 원하시는 분)께 공손해봐야 얼마만큼이나 공손해질까요? 매력이라곤 하나도 묻어나지 않는 그런 이름(존 스미스)밖엔 고를 수 없으셨나요? 왜요, 차라리 ‘말뚝’(노새의 끈을 매다는 말뚝을 의미함) 씨나 아님 ‘옷걸이’ 씨라고 하지 그러셨어요. 요번 여름엔 당신에 대해 엄청 생각했었어요. 오랜만에 제게 관심을 표하신 분이시기도 하고, 제가 가족 같은 그런 느낌을 받은 분이시라서요. 마치 누군가에게 속한 느낌이랄까, 아주 편안한 느낌이에요. 하지만, 뭐, 아저씨를 생각하면 할수록, 제 상상력이 영 힘을 발휘 못하네요. 일단 제가 지금까지 알아낸 사실 3가지가 있어요. 물론 당신에 대해서요. Ⅰ, 키가 크다. Ⅱ, 부자다. Ⅲ, 여자애들을 싫어하신다. 제 생각에 제가 당신을 ‘여자애를 싫어하는 미스터’라고 불러도 될 거 같은데. 그게 만약 모욕적으로 들리신다면, 부자 나리, 이것도 좀 무례하게 들리네요, 마치 돈이 전부인양 느껴질 수 있으니까. 하긴 부자다 아니 다는 극히 외적인 가치죠. 아마 당신도 계속 부자는 아닐 거 아녀요. 월스트리트(세계 금융시장의 중심가)에선 하루에도 수많은 똑똑한 젊은이들이 파산을 신고한다던데요. 하지만 뭐 당신은 앞으로도 계속 키가 커실 거잖아요! 그래서 전 당신을 키다리 아저씨라 부르기로 결심했답니다. 그렇게 불러도 되죠? 제가 아저씨의 별명을 지운 건 우리끼리의 비밀이에요… 절대 리펫 원장님껜 말하면 안 되요. 2분만 더 있음 밤 10시를 알리는 종이 울릴 거랍니다. 저희의 하루일과는 종이 결정하거든요. 종이 울리면 밥을 먹고, 종이 울리면 잠을 자고, 종소리와 함께 공부를 시작하죠. 나름 활기를 불어넣는다고 할까ㅋㅋ.\\n\\n하긴 뭐 하루 온종일 소방차를 끄는 말이 된 느낌이기도해요. :) (갑자기 종이 울리자) 거봐요 종이 울리네요! 어 불 꺼졌다. 그럼 안뇽. 참 학교규정 한번 잘 따르는 학생이라 생각했죠? ㅋㅋ 이게 다 〈존 그리어 고아원〉(여주인공이 나온 고아원이름)에서 몸에 밴 습관 때문이에요.\\n\\n당신을 너무도 존경하는,\\n\\n제루샤 에벗(여주인공이름)이.\\n\\n(2장 끝. 즉 여주인공이 키다리 아저씨에게 1번째로 보낸 편지의 전체 끝)', metadata={'source': './files/키다리아저씨2장.txt'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter()\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "loader.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='진 웹스터 소설\\n\\n『키다리 아저씨』 우리말 옮김\\n\\n당신\\n\\n키다리 아저씨께\\n\\n키다리 아저씨\\n\\n1장. “짱 나는 수요일”\\n\\n(원문→“우울한 수요일”)', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='매월 첫 번째 수요일은 너무도 끔직한 날이었다. 두려움 가득 그날을 기다렸다가 급히 서둘며 용기와 망각(잊음)으로 견디는 그런 날 말이다. 모든 바닥은 먼지 하나 없이 닦여져야 하고, 모든 의자엔 낙서 하나 없어야 했고, 모든 침대엔 구김 한 번 없어야 했다. 꿈틀대는 97명의 어린 고아들이 때밀이로 박박 때를 밀고 빗질을 하고 다름 질을 한 새 옷에', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='97명의 어린 고아들이 때밀이로 박박 때를 밀고 빗질을 하고 다름 질을 한 새 옷에 단추를 단단히 잠겨야했다. 또한 이 97명의 아이들은 예법들을 기억해야했고 만약 평의원(=고아원을 금전적으로 지원하는 분들)님들이 물으실 경우, “네, 선생님.” 또는, “아니오, 선생님.” 라고 대답해야했다. 고통스런 시간이었다. 특히나 고아들 중 가장 나이가 많은,', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='선생님.” 라고 대답해야했다. 고통스런 시간이었다. 특히나 고아들 중 가장 나이가 많은, 가련한 ‘제루샤 에벗’(여주인공이름. 에벗은 남자이름임)에게 있어서 그 시간은 자신이 모든 짐을 짊어져야하는 그런 시간이었다. 이전의 것과 마찬가지로, 이 특별했던 첫 번째 수요일도 마침내 꾸억꾸억 종료를 향해 나아가고 있었다. 고아원 손님들을 위해 샌드위치들을 다', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='마침내 꾸억꾸억 종료를 향해 나아가고 있었다. 고아원 손님들을 위해 샌드위치들을 다 만든 후 식료품저장실을 벗어나, 제루샤(여주인공 이름)는 자신의 정규 일을 마무리 짓기 위해 위층으로 향했다. 특히나 ‘바’(원문→에프) 방에 무척 신경을 기울였는데, 그 방에는 4잘부터 7살에 이르는 11명의 어린 꼬마들이 일렬로 널어진 11개의 간이침대에 거주하고 있는', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='7살에 이르는 11명의 어린 꼬마들이 일렬로 널어진 11개의 간이침대에 거주하고 있는 방이었다. 제루샤는 아이들을 모은 다음, 구겨진 옷들을 곱게 펴주고 코를 닦아준 다음 그들이 질서 있게 줄을 이루며 식당으로 출발하도록 했다. 그 애들에게, 빵과 우유 그리고 자두 푸딩(서양과자)과 함께 축복받은 30분을 약속해주고 있는 식당 말이다. 그런 다음', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='자두 푸딩(서양과자)과 함께 축복받은 30분을 약속해주고 있는 식당 말이다. 그런 다음 제루샤(여주인공이름)는 창가 쪽 의자 위에 앉아 고동치는 관자놀이(귀와 눈 사이에, 오목하게 들어간 곳)를 차가운 창문에 기대었다. 이날 아침 5시부터 한시도 앉지 못했더랬다. 사람들이 시키는 일을 하느라, 신경질적인 보모가 꾸짖고 다그치는 통에 말이다. 리펫 원장은,', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='시키는 일을 하느라, 신경질적인 보모가 꾸짖고 다그치는 통에 말이다. 리펫 원장은, 평의원(=이사)들과 부인 방문객들과 얼굴을 마주하며 차분하고 위엄 있게 행동했지만 무대 뒤에선 항상 그런 건 아니었기 때문이다. 제루샤는, 고아원 경계 자국을 내고 있는 키 큰 철제 울타리 너머로, 넓게 뻗은 언 잔디밭 저쪽을 바라다보았다. 그 아래로는 시골의 사유지들이', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='울타리 너머로, 넓게 뻗은 언 잔디밭 저쪽을 바라다보았다. 그 아래로는 시골의 사유지들이 섞인 울퉁불퉁한 산등성이들이 보였다. 마을의 뾰족탑들이 듬성한 나무들 가운데로 높게 솟아나 있었다. 어쨌든 그날은… 아주 성공적으로 끝이 났다. 적어도 제루샤(여주인공이름)가 아는 한은 말이다. 평의원 분들과 함께 방문한 후원인 분들은 한 바퀴 둘러본 후 제출된', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='아는 한은 말이다. 평의원 분들과 함께 방문한 후원인 분들은 한 바퀴 둘러본 후 제출된 보고서들을 읽고 차(마시는 차)를 한 잔씩 했다. 그리고 이젠 그들도 서둘러 자신들을 기다리는 활기찬 벽난로 가가 있는 집으로 돌아들 가고 있는 중이었다. 다음 달에 있을 그들의 방문이 어떤 성가심을 주는지 망각한 채 말이다. 제루샤는 호기심 가득 그들을 쳐다보며 몸을', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='어떤 성가심을 주는지 망각한 채 말이다. 제루샤는 호기심 가득 그들을 쳐다보며 몸을 숙이고 있었다… 동경의 눈, 횃불… 고아원 정문을 굴러나가고 있는 마차들과 자동차들의 행렬들. 상상 속에서, 제루샤는 첫 번째 마차를 따라 산중턱에 있던 어느 큰 저택으로 향했다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='자신이 마차 좌석에 몸을 파묻고는 무심한 듯 “그만 집으로”라고 마부에게 중얼거리고 있는, 모피 코트와 깃털로 테두리를 다듬은 벨벳 모자를 한 자신의 모습을 그려보았다. 하지만 그 큰 집 문지방에 막 다다랐을 때 형상(그림)이 점점 흐려졌다. 제류샤는 상상력을 가졌다… 풍부한 상상력, 그래서인지 리렛 원장은 제루샤에게 말하길, “주의하지 않음 곤란에', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='풍부한 상상력, 그래서인지 리렛 원장은 제루샤에게 말하길, “주의하지 않음 곤란에 부딪힐 거”라고…, 하지만 그 예리한 상상력에도 불구하고, 도무지 그 귀부인 들어설 저택의 현관문 너머는 상상이 잘 안 되었다. 불쌍하고, 열성적이고, 모험적인 고아 제루샤는, 이제 17살이었다. 그녀는 결코 평범한 집에 발을 들여놓아본 적이 없었다. 그래서 도무지 다른', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='17살이었다. 그녀는 결코 평범한 집에 발을 들여놓아본 적이 없었다. 그래서 도무지 다른 인류, 그러니까 고아원과는 전혀 일면식이 없는 다른 인류가 어떤 일상의 생활을 영위하는지 상상을 해볼 수 없었던 것이다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='(▼아래는 고아원 합창단 소년이 장난으로 노래 부르는 소리) 〈제―루―샤  에―벗 부른다 원―장 실에서 내 생각엔 서두르는 게 좋을 듯!〉', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='토미 딜런(이름 알 필요 없음. 한 번만 나오는 이름임)은 합창단에 속해 있었는데, 계단을 올라와 복도를 따라 거닐면서 노래를 부르고 있었다. ‘바’ 방이 가까워짐에 따라 노래는 점점 더 커지고 있었따. 제루샤가 창문에서 머리를 떼어 다시 현실 속 문제들로 돌아와, “누가 찾는데?”라며 걱정을 한 가득 담아, 토미의 노래에 끼어들었다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='(▼토미가 노래로 대답하는 것임) 〈리펫 원장이 급히 찾아, 원장실에서, 내 생각에 그녀가 미친 것 같아. 아―아―멘!〉', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='토미(고아원 합창단 단원. 이름 알 필요 없음. 다시 안 나오는 이름임)가 비록 기도문 식으로 노래를 불렀지만, 하지만 그의 말투에 전혀 악의적인 기색은 찾을 수 없었다. 왜냐면 죄를 범한 누이가 화를 내고 있는 여간수(원장)에게 사무실로 호출 당하면 아무리 기가 센 고아원생이라도 동정심을 느끼게 마련인데 그렇지 않았고, 또한 제루샤가 토미의 팔을 홱', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='센 고아원생이라도 동정심을 느끼게 마련인데 그렇지 않았고, 또한 제루샤가 토미의 팔을 홱 잡아당기거나 콧물을 너무 세게 문질러 없애긴 했지만, 그럼에도 불구하고 토미는 제루샤를 좋아했기 때문이다. 제루샤는 잠자코 향했다. 하지만 이마엔 벌써 두 줄이 생긴 상태였다. ‘뭐가 잘못된 걸까’, 하고 제루샤는 생각했다. ‘오늘 나온 샌드위치가 충분히 두덮지', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='‘뭐가 잘못된 걸까’, 하고 제루샤는 생각했다. ‘오늘 나온 샌드위치가 충분히 두덮지 못해서일까? 아님 땅콩 케이크에 땅콩 껍질이라도 들어간 걸까? 아님 틈(구멍)에 끼어 여자 방문객 한 분의 스타킹에 구멍이라도 난 걸까? 그게 아니라면… 아 설마!… 우리 ’바‘ 방에 있는 천사 아가들 중 한 명이 평의원 한 분께 말대꾸를 했나?” 길고 낮은 복도엔 불도', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='있는 천사 아가들 중 한 명이 평의원 한 분께 말대꾸를 했나?” 길고 낮은 복도엔 불도 켜져 있지 않았다. 제루샤가 아래로 내려와 보니, 마지막 남은 평의원 한 분이 출발지점에 서 계시다가 열린 문을 통해 ‘포르트 코셰르’(현관 앞의 마차 대는 곳. 사진링크 ▶ http://me2.do/FLzLgF75 )로 걸어가고 계셨다. 제루샤는 흡사 그 남성의', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='http://me2.do/FLzLgF75 )로 걸어가고 계셨다. 제루샤는 흡사 그 남성의 첫인상이 키가 엄청 커다는 인상을 받았더랬다. 커브길에서 자신을 기다리고 있는 자동차를 향해 그 남성이 손을 흔들었다. 자동차가 갑자기 움직이면서 정면에서 접근함에 따라, 눈부신 헤드라이트(자동차의 불빛)가 그 분의 그림자를 벽 안쪽으로 날카롭게(원문→뚜렷이)', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='눈부신 헤드라이트(자동차의 불빛)가 그 분의 그림자를 벽 안쪽으로 날카롭게(원문→뚜렷이) 내던졌다. 이상하리만치 길게 늘어진 다리들과 팔들이 바닥을 따라 복도의 벽 천정까지 길게 그림자를 그리웠다. 어쩜 세상에, 저건 꼭 무지막지하게 큰 ‘장님거미’(=거미의 일종=키다리 아저씨. 키다리 아저씨의 원래 영어 제목이 ‘장님거미’임. 우리말로 하면 ‘다리가 긴', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='아저씨. 키다리 아저씨의 원래 영어 제목이 ‘장님거미’임. 우리말로 하면 ‘다리가 긴 꺽다리’란 뜻임) 한 마리가 꿈틀대고 있는 것 같잖아. 자동차 헤드라이트에 눈살을 찌푸리다 급 웃음꽃이 핀 제루샤는 원래가 해맑은 영혼이었다. 그래서 전혀 웃기지 않은 상황 속에서도 웃음꽃을 피울 수 있었던 것이다. 평의원의 답답한 이미지에서 일종의 재미를 찾은 건', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='웃음꽃을 피울 수 있었던 것이다. 평의원의 답답한 이미지에서 일종의 재미를 찾은 건 기대치 않은 소득이었다. 이 사소한 에피소드(사건)에 무척 기분이 좋아진 제루샤는 원장실로 계속 가, 미소 짓는 얼굴로 리펫 원장(이름 몰라도 됨. 다시 안 나옴) 앞에 나타났다. 그런데 얼씨구, 이 나이 지긋한 원장님 또한 정확히 말해 미소는 아니었지만 나름 상냥한', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='그런데 얼씨구, 이 나이 지긋한 원장님 또한 정확히 말해 미소는 아니었지만 나름 상냥한 태도로 제루샤를 맞아주었는데, 손님을 맞이하기 위해 입었던 옷만큼이나 다채로운 표정을 짓고 계셨다. “제루샤, 앉거라, 네게 해줄 말이 하나 있다.” 제루샤는 가장 가까이에 있던 의자에 움츠리듯 주저앉아 숨죽인 채 기다렸다. 좀 전 그 자동차의 불빛이 원장실의 창문을', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='의자에 움츠리듯 주저앉아 숨죽인 채 기다렸다. 좀 전 그 자동차의 불빛이 원장실의 창문을 빠르게 훑고 지나갔다. 리펫 원장이 그것을 뒤따라 흘낏 보았다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='(리펫 원장의 대사→) “너도, 방금 막 나가신 신사 분을 목격했겠지?” (제루샤의 대사→) “등만 본 걸요.” “그는 우리 평의원들 중에서도 가장 재력과 사회적 영향력을 갖춘 사람이란다, 지금까지 상당한 액수의 금액을 고아원 기금으로 기부도 하셨고 말이다. 엄밀히 말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의 조건으로 내거셨거든.” 이 부분에서 제루샤의 눈이 살짝 휘둥그레졌다. 별난 평의원에 관해 얘기하려 자신을 원장실로 부르는 건 원장의 평소 행동이 아니었기 때문이다. “이 신사 분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리 벤톤’과 ‘헨리 프리즈’ 말이다. (두 소년 모두 몰라도 되는 이름임. 다시 안 나옴) 그 애들은 미스터… 이 평의원께서 후원해 주셨고, 그 애들도 열심히 노력한 결과 나름 성공할 수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두 소년들만 초점이 맞추어져 있었단다. 고아원에 있는 여자애들에겐 전혀 관심을 표하시지 않으셨지. 여자애들이 후원을 받을만한가는 둘째치고서라도 말이다. 그래 내가 네(제루샤)게 말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.” “네,', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.” “네, 원장님.”라며 제루샤가 옹알거렸다. 이 부분에서 자신에게 뭔가 대답을 요구하는 것 같았기 때문이다. “오늘 정기 모임에서는, 네(여주인공인 제루샤) 장래에 관한 얘기가 꺼내어졌다.” 리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에 얘기를 천천히 다시 시작했다. “너도 알다시피, 대개의 경우에는, 16살이 되면(제루샤는 현재 17살임) 여기에 계속 있을 수 없다. 하지만 넌 예외였다. 네가 14살에 고아원 학교를 마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건 아니었다만. 결국 내 주장에 따라 넌 근처 마을에 있는 고등학교에 여기에 있으면서 다니는 게 허락되었고, 이제 그 마저도 다 끝마쳤다. 물론 그 이상의 교육(대학교)을 고아원에서 지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱 말이다.” 지난 2년 동안 제루샤가 열심히 생활했다는 사실과 고아원의 편의를 받아 첫 번째 학업 과정과 두 번째 학원 과정을 마친 사실과 아이들을 돌보며 고아원에 머물고 있는 현재의 사정을, 리펫 원장은 쭉 훑어나갔다. “이미 말한 대로, 평의원 회의에서 네 장래에', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='사정을, 리펫 원장은 쭉 훑어나갔다. “이미 말한 대로, 평의원 회의에서 네 장래에 대한 안건이 상정되어 네 경력이 화제로 다루어졌단다… 아주 철저히 말이다.” 리펫(여자이름) 원장은 독(항아리) 안에 든 이 죄수의 유무죄를 따지려는 듯 비난하는 눈초리로 찬찬히 살폈다. 그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='살폈다. 그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의 성적표에서 유달리 참담했던 과목의 성적을 기억해냈기 때문은 아니었다. “물론 네게 줄 수 있는 배려들 중 하나는 네가 일을 시작할 수 있는 알맞은 직책을 찾아주는 것일 수도 있다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='하지만 네 학업성적들 중 어학관련 성적들이 워낙에 우수해서 말이다. 특히나 국어(영어) 성적이 놀랍더구나. 오늘 방문한 위원 중 한 분인 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴)는 학교 이사시기도 한데, 그녀가 말하길 네(여주인공인 제루샤) 수사학(언어의 사용을 연구하는 학문) 선생님과 얘기를 나눠보았는데 선생님이 너에 대해 호평을 하셨다고', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='사용을 연구하는 학문) 선생님과 얘기를 나눠보았는데 선생님이 너에 대해 호평을 하셨다고 하더라. 그리곤 프리처드 여사가 위원회에서, 네(여주인공인 제루샤)가 「짱 나는 수요일」(원문→우울한 수요일)이라고 제목 붙인 에세이 한 편도 소리 내 읽으셨단다.” 그 말에 제루샤(여주인공이름)의 얼굴이 붉어졌다. “그건(짱 나는 수요일이란 에세이. 고아원에', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='제루샤(여주인공이름)의 얼굴이 붉어졌다. “그건(짱 나는 수요일이란 에세이. 고아원에 평의원들이 방문하는 날이 매월 첫 번째 수요일이라 에세이 제목에 수요일이 들어감) 네게 은덕을 베푼 시설(고아원)을 조롱하면서도 고마움은 거의 비취지 않는 글 같았다만. 그런 글에 과연 위원회에서 읽혀질 만큼 가치가 있을지 의문이었다만. 어쨌든 네(제루샤.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='그런 글에 과연 위원회에서 읽혀질 만큼 가치가 있을지 의문이었다만. 어쨌든 네(제루샤. 여주인공이름)겐 다행스럽게도, 그 자리에 계셨던, 미스터… 방금 나가셨던 그 신사 분께선… 음 그 분은 좀 무분별한 유머 감각을 가진 듯 하더구나. 그 건방진 에세이 한 편과 네 국어성적에 힘입어, 그분이 너를 대학교 보내주시겠다고 제안했단다.” “대학에요?”라며 눈이', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='힘입어, 그분이 너를 대학교 보내주시겠다고 제안했단다.” “대학에요?”라며 눈이 휘둥그레져선 제루샤(여주인공이름)가 말했다. 리펫 원장이 고개를 끄덕였다. “그(키다리 아저씨)는 그 문제를 나와 상의하러 마지막까지 남아 있었던 것이다. 원래가 평의원 분들은 유별난 데가 많은데, 굳이 말하자면, 그 신사 분은 좀 상식을 벗어난 별난 데가 있다. 그 분은', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='데가 많은데, 굳이 말하자면, 그 신사 분은 좀 상식을 벗어난 별난 데가 있다. 그 분은 네(여주인공) 창의력을 믿는다더구나. 그래서 네게 작가가 될 수 있는 교육을 받게 해줄 계획이라더라.” “작가요?” 어찌나 정신이 얼얼한지 제루샤는 다만 리펫 원장의 마지막 단어(작가)를 반복하기만 했다. (리펫 원장의 대사→) ”그것이 그(키다리 아저씨)의', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='단어(작가)를 반복하기만 했다. (리펫 원장의 대사→) ”그것이 그(키다리 아저씨)의 희망이다. 그래서 어찌될 지는 곧 알게 되겠지. 일단 그 분은 네게 제법 넉넉한 용돈을 주실 게다, 거의, 용돈이라곤 생전 한 번 받아 본 적이 없는 여자애에게 있어선 아주 넉넉한 금액일 게다. 하지만 (읽기 쉽게 문단을 여러 번 나눔. 모두 원장님의 긴 대사임)', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='금액일 게다. 하지만 (읽기 쉽게 문단을 여러 번 나눔. 모두 원장님의 긴 대사임) 세부적인 사항은 그 분이 짜주실 게다, 난 일일이 제안을 하고 싶지 않더라만. 넌 일단 여름 동안은 여기(고아원) 머물러야 한다. 그리고 프리처드 여사(몰라도 되는 이름임. 다시 안 나옴. 학교의 이사)께서 네 채비(여행준비)를 관리해주시기로 친절하게도 제안하셨단다. 네', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='나옴. 학교의 이사)께서 네 채비(여행준비)를 관리해주시기로 친절하게도 제안하셨단다. 네 식대(식사비용)와 수업료는 대학교로 바로 지불이 될 거다, 넌 거기에 머무는 4년 동안 추가적으로 매달 70만원(원문→35달러. 이해가 쉽도록 70만원으로 해석했음. 전혀 근거가 없는 계산법임^^)을 용돈으로 받게 될 거다. 그 정도 용돈이면 네가 한 점 부끄러움', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='없는 계산법임^^)을 용돈으로 받게 될 거다. 그 정도 용돈이면 네가 한 점 부끄러움 없이 다른 학생들과 동등하게 생활할 수 있을 게다. 용돈은 매달 한 번씩 그 신사 분(키다리 아저씨)의 개인 비서를 통해 네게 보내어질 게다. 넌 그 답례로 그분께 매달 한 차례 답례 편지를 써야 한다.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='그건(답례편지)… 용돈을 주시는 것에 대한 감사 편지여서는 안 된다. 그 분은 그런 식의 언급을 극도로 싫어하시는 분이시니까. 하지만 넌 편지에서 네 학업의 진도와 네 매일 매일의 일상들의 세부사항들을 그 분께 말씀드려야 한다. 만약 네 부모님들께서 살아계셨다면 네가 적어 보냈을 그런 안부 편지를 넌 그분께 편지로 보내면 되는 거야.” (←큰 따옴표 끝.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='적어 보냈을 그런 안부 편지를 넌 그분께 편지로 보내면 되는 거야.” (←큰 따옴표 끝. 리펫 원장의 대사 끝) (리펫 원장의 대사 계속→) “네가 쓴 편지들은 존 스미스 씨 앞으로 비서(키다리 아저씨의 개인비서)를 통해 안전하게 전달될 거다. 물론 널 돕기로 한 그 분의 성함이 존 스미스란 얘기를 아니다. 어쨌든 그 분은 자신이 드러나는 걸 꺼리시니까.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='분의 성함이 존 스미스란 얘기를 아니다. 어쨌든 그 분은 자신이 드러나는 걸 꺼리시니까. 너(여주인공)에게 그 분은 그냥 존 스미스란 얘기일 뿐이다. 굳이 그 분이 네게서 편지를 요구하시는 건, 그 분이 생각하기에 문학적 표현을 기르는데 손 편지만한 게 없다 여기시기 때문이다. 또한 그 분은 네가 나아가는 바를 그때그때 알기를 바라신다. 물론 그 분이 네', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='때문이다. 또한 그 분은 네가 나아가는 바를 그때그때 알기를 바라신다. 물론 그 분이 네 편지에 답하시는 일을 결코 없을 게다. 또한 네 편지엔 그것에 대해 어떤 사소한 언급도 있어선 아니 된다. 그 분은 손 편지 쓰는 걸 극히 싫어하신다. 그러니 넌 그 분께 부담을 안겨선 안 돼. 만약 네가 퇴학을 당하는 경우와 같은 그런 어쩔 수 없는 상황이 벌어져', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='안겨선 안 돼. 만약 네가 퇴학을 당하는 경우와 같은 그런 어쩔 수 없는 상황이 벌어져 답장이 꼭 필요할 것 같으면, 물론 그런 일이 없어야겠지만, 넌 ‘그리그스’(영어단어 ‘그리그’는 쾌활한 사람이란 뜻임. 귀뚜라미란 뜻도 있음) 씨와 연락을 취할 수도 있을 게다. 물론 그리그스 씨는 그 분의 개인비서다. 매월 부쳐야하는 이 편지는 네 입장에선', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='게다. 물론 그리그스 씨는 그 분의 개인비서다. 매월 부쳐야하는 이 편지는 네 입장에선 절대적으로 준수해야하는 의무다. 스미스 씨(키다리 아저씨의 가명)가 요구하는 유일한 보상이니, 넌 그 편지들을 네가 지불하는 계산서인양 꼼꼼히 보내야한다. 내 생각이다만, 편지는 항상 예의발라야 되겠고 네 학업의 성과들이 반영되어야 되겠지. 우선은 〈존 그리어', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='편지는 항상 예의발라야 되겠고 네 학업의 성과들이 반영되어야 되겠지. 우선은 〈존 그리어 고아원〉(←고아원이름임)의 평의원 한 분께 공손히 편지를 보내야한다는 것만 기억하고 있거라.” (←큰 따옴표 끝. 리펫 원장의 대사 끝) 제루샤의 두 눈은 오랫동안 문만 바라보고 있었다. 그녀의 머릿속엔 지금 흥분의 수레바퀴가 돌고 있어 리펫 원장의 상투적인', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='바라보고 있었다. 그녀의 머릿속엔 지금 흥분의 수레바퀴가 돌고 있어 리펫 원장의 상투적인 말투로부터 벗어나기만을 바랐을 뿐이기 때문이다. 제루샤가 시험 삼아 자리에서 일어나 한발작 뒷걸음을 쳐보았다. 그러자 리펫 원장이 손짓으로 “좀 더 기다리라”고 말했다. 그건 리펫 원장의 일장연설이 한 차례 더 있을 예정임을 의미했다. “네게 온 이 지극히 드문', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='리펫 원장의 일장연설이 한 차례 더 있을 예정임을 의미했다. “네게 온 이 지극히 드문 행운에 대해 네가 적절히 감사할 줄 안다고 내가 믿어도 되겠지? 도대체 이런 흔치 않은 기회를 거머쥔 여자 아이가 이 세상에 일찍이 너 말고 누가 또 있었겠니? 그러니 넌 이 점을 분명히 기억하고서 앞으로 행동을…” “전(=저는)… 아, 네, 감사합니다, 원장님. 방금', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='분명히 기억하고서 앞으로 행동을…” “전(=저는)… 아, 네, 감사합니다, 원장님. 방금 생각난 건데, 제가 지금 ‘프레디 퍼킨즈’(고아 이름.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='다시 안 나오는 이름임)의 바지에 헝겊을 깁다 온 걸 깜빡해서요.” 문이 뒤에서 “꽝!”하고 닫히자, 리펫 원장은 장황한(=긴) 연설을 하다 말고 아래턱을 쭉 내린 상태로 문을 바라보았다.\\n\\n(1장 끝)', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='(1장 끝)\\n\\n(여기까지가 1장 끝입니다. 2장부터는 한 달에 한 번씩 키다리 아저씨에게 보낸 편지들입니다. 이후, 1장, 2장과 같이 ‘장’은 제가 붙인 거고 원문엔 ‘장’의 구분이 없습니다.)\\n\\n2장. 키다리 아저씨', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='(옮긴이 설명 1 : 읽기 쉽게, 여주인공이 한 달에 한 번씩 키다리 아저씨에게 보낸 편지마다 새로운 ‘장’을 붙이겠습니다. 2장, 3장,...30장 이런 식으로요~ 2장=첫 번째 편지. 3장-두 번째 편지.... 30장=29번째로 보낸 편지) (옮긴이 설명 2 : 이제부터는 편지입니다. 헷갈릴 수 있는데 소설이 편지의 형식입니다. 서점에 가셨을 때', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content=': 이제부터는 편지입니다. 헷갈릴 수 있는데 소설이 편지의 형식입니다. 서점에 가셨을 때 키다리 아저씨 번역서를 한 번 훑어보시면 소설의 이해가 빠릅니다. 말이 편지 형식이지 인터넷으로 처음 접하면 뭔지 모를 수가 있거든요.)', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='제루샤 에벗 양이\\n\\n키다리 아저씨인 스미스 씨에게\\n\\n보낸 편지들\\n\\n(제가 추가한 제목)\\n\\n2장. 대학교 1학년 (17세)\\n\\n(본문 시작) 퍼거슨 강당 215호에서 9월 24일 (여주인공 17세. 대학교 1학년)\\n\\n고아들을 대학에 보내주시는 고마운 평의원(=키다리 아저씨) 분께,', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='캭, 저 왔어요! 어제 열차로 자그마치 4시간 동안을 여행했답니다. 어찌나 묘한 감동이던 지요, 전엔 한 번도 기차를 타본 적이 없었걸랑요. 대학교(대학원을 두지 않고 대학교의 학부만 있는 대학교)는 엄청 커요, 정말 눈이 휘둥그레지는 곳이랍니다. 이불 떠나서 전 이곳에서 매번 길을 잃거든요. 제가 좀 덜 혼란스러울 때 상세히 설명한 편지를 부칠까 해요.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='매번 길을 잃거든요. 제가 좀 덜 혼란스러울 때 상세히 설명한 편지를 부칠까 해요. 그 편지엔 제 수업에 대한 것들도 들어갈 거고요. 수업은 월욜 아침까진 시작하지 않아요, 그런데 오늘이 토욜 밤인 건 함정~ 하지만 익숙해지고 싶어서 편지를 쓰고 싶지 뭐예요. 알지도 못하는 사람에게 편지를 쓰자니 기분이 묘한 것 같아요. 아니 그냥 편지 쓰는 것 자체가', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='못하는 사람에게 편지를 쓰자니 기분이 묘한 것 같아요. 아니 그냥 편지 쓰는 것 자체가 제겐 야릿하거든요. 하긴 지금껏 편지라곤 세 통 내지는 네 통 정도 써본 게 다이니까요. 그러니 지금 보내드리는 편지가 편지의 기본 형식을 취하지 못했더라도 너그러이 이해봐레요~ 어제 아침 떠나오기 전, 리펫 원장님과 전 참 심각한 대화를 나누었답니다. 원장님께선', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='어제 아침 떠나오기 전, 리펫 원장님과 전 참 심각한 대화를 나누었답니다. 원장님께선 앞으로 남은 제 생애 동안 어떻게 행동해야할지를 말씀하셨죠, 누누이 말하듯, 제게 이토록 친절을 베풀고 계시는 그 신사 분(키다리 아저씨)께 특별히 유의하라면서요. 그래서 전 편지를 쓰면서도 아주 공손해지려고 주의하고 있어요. 하지만 존 스미스 씨(키다리 아저씨의', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='편지를 쓰면서도 아주 공손해지려고 주의하고 있어요. 하지만 존 스미스 씨(키다리 아저씨의 가명)라 불리길 원하시는 분(즉 가명으로 불리길 원하시는 분)께 공손해봐야 얼마만큼이나 공손해질까요? 매력이라곤 하나도 묻어나지 않는 그런 이름(존 스미스)밖엔 고를 수 없으셨나요? 왜요, 차라리 ‘말뚝’(노새의 끈을 매다는 말뚝을 의미함) 씨나 아님 ‘옷걸이’', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='왜요, 차라리 ‘말뚝’(노새의 끈을 매다는 말뚝을 의미함) 씨나 아님 ‘옷걸이’ 씨라고 하지 그러셨어요. 요번 여름엔 당신에 대해 엄청 생각했었어요. 오랜만에 제게 관심을 표하신 분이시기도 하고, 제가 가족 같은 그런 느낌을 받은 분이시라서요. 마치 누군가에게 속한 느낌이랄까, 아주 편안한 느낌이에요. 하지만, 뭐, 아저씨를 생각하면 할수록, 제 상상력이', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='아주 편안한 느낌이에요. 하지만, 뭐, 아저씨를 생각하면 할수록, 제 상상력이 영 힘을 발휘 못하네요. 일단 제가 지금까지 알아낸 사실 3가지가 있어요. 물론 당신에 대해서요. Ⅰ, 키가 크다. Ⅱ, 부자다. Ⅲ, 여자애들을 싫어하신다. 제 생각에 제가 당신을 ‘여자애를 싫어하는 미스터’라고 불러도 될 거 같은데. 그게 만약 모욕적으로 들리신다면, 부자', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='싫어하는 미스터’라고 불러도 될 거 같은데. 그게 만약 모욕적으로 들리신다면, 부자 나리, 이것도 좀 무례하게 들리네요, 마치 돈이 전부인양 느껴질 수 있으니까. 하긴 부자다 아니 다는 극히 외적인 가치죠. 아마 당신도 계속 부자는 아닐 거 아녀요. 월스트리트(세계 금융시장의 중심가)에선 하루에도 수많은 똑똑한 젊은이들이 파산을 신고한다던데요. 하지만 뭐', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='중심가)에선 하루에도 수많은 똑똑한 젊은이들이 파산을 신고한다던데요. 하지만 뭐 당신은 앞으로도 계속 키가 커실 거잖아요! 그래서 전 당신을 키다리 아저씨라 부르기로 결심했답니다. 그렇게 불러도 되죠? 제가 아저씨의 별명을 지운 건 우리끼리의 비밀이에요… 절대 리펫 원장님껜 말하면 안 되요. 2분만 더 있음 밤 10시를 알리는 종이 울릴 거랍니다. 저희의', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='말하면 안 되요. 2분만 더 있음 밤 10시를 알리는 종이 울릴 거랍니다. 저희의 하루일과는 종이 결정하거든요. 종이 울리면 밥을 먹고, 종이 울리면 잠을 자고, 종소리와 함께 공부를 시작하죠. 나름 활기를 불어넣는다고 할까ㅋㅋ.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='하긴 뭐 하루 온종일 소방차를 끄는 말이 된 느낌이기도해요. :) (갑자기 종이 울리자) 거봐요 종이 울리네요! 어 불 꺼졌다. 그럼 안뇽. 참 학교규정 한번 잘 따르는 학생이라 생각했죠? ㅋㅋ 이게 다 〈존 그리어 고아원〉(여주인공이 나온 고아원이름)에서 몸에 밴 습관 때문이에요.\\n\\n당신을 너무도 존경하는,\\n\\n제루샤 에벗(여주인공이름)이.', metadata={'source': './files/키다리아저씨2장.txt'}),\n",
       " Document(page_content='당신을 너무도 존경하는,\\n\\n제루샤 에벗(여주인공이름)이.\\n\\n(2장 끝. 즉 여주인공이 키다리 아저씨에게 1번째로 보낸 편지의 전체 끝)', metadata={'source': './files/키다리아저씨2장.txt'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "loader.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "loader.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03637292483622222,\n",
       " -0.0071586398622948974,\n",
       " -0.03374136096384863,\n",
       " -0.02863455944917959,\n",
       " -0.02683675658053588,\n",
       " 0.03457512196757851,\n",
       " -0.012441311878261738,\n",
       " -0.007816531296049613,\n",
       " 0.0019297060938630506,\n",
       " -0.0026511067466092933,\n",
       " 0.024700239119034212,\n",
       " -0.002454065186273913,\n",
       " -0.0057744625228963314,\n",
       " -0.0029849377163842583,\n",
       " 0.006670106656291796,\n",
       " -0.0030223920204245553,\n",
       " 0.03379347032808977,\n",
       " -0.0015111960102122777,\n",
       " 0.021052524017505653,\n",
       " -0.009028093572431494,\n",
       " -0.021703902246391547,\n",
       " 0.010369931122061495,\n",
       " 0.006302078217741605,\n",
       " 0.007093501760009517,\n",
       " -0.012252412638919696,\n",
       " 0.0008191073405129948,\n",
       " 0.005872168977832424,\n",
       " -0.009835801756686078,\n",
       " -0.0030451903329413725,\n",
       " -0.0247132664600945,\n",
       " 0.01078029888471893,\n",
       " -0.013822232382395232,\n",
       " -0.024491797936779105,\n",
       " -0.014108838542334686,\n",
       " 0.00244429444764804,\n",
       " -0.018968115920245127,\n",
       " 0.0005850185223377864,\n",
       " -0.011373053147510906,\n",
       " 0.01813435305386997,\n",
       " -0.00995956335940406,\n",
       " 0.013118744789268201,\n",
       " -0.01129488723850392,\n",
       " -0.009158368845679617,\n",
       " -0.009712040153968099,\n",
       " -0.026432903419731223,\n",
       " 0.007008822646133709,\n",
       " -0.00968598454052489,\n",
       " 0.004797396110890129,\n",
       " -0.01663618275490336,\n",
       " 0.02505198291559773,\n",
       " 0.003520695965053529,\n",
       " 0.017808663939427025,\n",
       " -0.017417836257037377,\n",
       " -0.004461936490651969,\n",
       " -0.012877735254362381,\n",
       " -0.017991048576916285,\n",
       " -0.004201385478494404,\n",
       " 0.007699282898200456,\n",
       " 0.0024980331608443524,\n",
       " -0.034861727196195326,\n",
       " -0.006819923406791666,\n",
       " 0.016049943093964167,\n",
       " 0.0029035156706041813,\n",
       " 0.005807031341208363,\n",
       " -0.00385615535246103,\n",
       " 0.006399784672677698,\n",
       " 0.018968115920245127,\n",
       " 0.005240332691859596,\n",
       " 0.016779487231857047,\n",
       " 0.012916817277543235,\n",
       " 0.027409968900414788,\n",
       " 0.026615288057220486,\n",
       " 0.011503328420759028,\n",
       " -0.009764150449531874,\n",
       " 0.017978021235856,\n",
       " -0.021026469335385083,\n",
       " -0.006963226486761393,\n",
       " 0.0037454210908033337,\n",
       " -0.013613791200140125,\n",
       " -0.007334511760576656,\n",
       " 0.01846004030566764,\n",
       " -0.01585453111541462,\n",
       " -0.009913966734370425,\n",
       " 0.015072877613280604,\n",
       " 0.020049401992056244,\n",
       " 0.0060350135350538976,\n",
       " -0.012441311878261738,\n",
       " 0.021690873042685986,\n",
       " -0.013483515926892,\n",
       " -0.02941621108866833,\n",
       " 0.01846004030566764,\n",
       " 0.024491797936779105,\n",
       " -0.003139639952612394,\n",
       " 0.027149418353918542,\n",
       " -0.01909839119349325,\n",
       " -0.0010536032048886722,\n",
       " -0.022941518273571358,\n",
       " 0.023879501731074067,\n",
       " 0.007484328511076525,\n",
       " 0.0019411052501214592,\n",
       " 0.014252142087965733,\n",
       " 0.01934591439892921,\n",
       " -0.008389743615928523,\n",
       " -0.0023237894473644707,\n",
       " -0.018629399464741896,\n",
       " -0.014812326135461719,\n",
       " -0.019671603513372157,\n",
       " -0.007282401465012878,\n",
       " 0.019384996422110067,\n",
       " 0.0015087533837634744,\n",
       " -0.007139098385043151,\n",
       " 0.02386647439001378,\n",
       " -0.010467638042658907,\n",
       " -0.03718063115783153,\n",
       " -0.0076667140798884256,\n",
       " -0.013470488585831716,\n",
       " -0.001727779047799404,\n",
       " -0.004813680287215486,\n",
       " -0.012512963185415941,\n",
       " -0.018707563511103604,\n",
       " 0.019020225284486266,\n",
       " 0.011034336692007674,\n",
       " 0.016857651278218755,\n",
       " -0.0016032031198498255,\n",
       " 0.014760215839897941,\n",
       " 0.006201114461879122,\n",
       " -0.011926723524476749,\n",
       " -0.020505366379747314,\n",
       " -0.000308997251632808,\n",
       " 0.006976253827821678,\n",
       " 0.03444484855697566,\n",
       " -0.003488126913910839,\n",
       " -0.006526803576322069,\n",
       " -0.009125800493028904,\n",
       " -0.024947762324470175,\n",
       " 0.025455836076402383,\n",
       " -0.010363417451531354,\n",
       " 0.026315655487543384,\n",
       " -0.027305748309287232,\n",
       " -0.02717547303603911,\n",
       " -0.003983173790444082,\n",
       " 0.02806134712930068,\n",
       " 0.002569684700829216,\n",
       " -0.00932121340290109,\n",
       " -0.021391240473008884,\n",
       " 0.0005671056373415705,\n",
       " -0.010031214666558264,\n",
       " -0.01672737600497063,\n",
       " 0.011438190784134966,\n",
       " -0.007757907329955694,\n",
       " -0.00020314838839188064,\n",
       " 0.015072877613280604,\n",
       " 0.010526262008752826,\n",
       " 0.0034848700786457676,\n",
       " 0.0062043717628055125,\n",
       " 0.01077378521418879,\n",
       " -0.004273036785648608,\n",
       " 0.004719230667544465,\n",
       " -0.007595062772734221,\n",
       " -0.020140595242123513,\n",
       " -0.007842585978170183,\n",
       " 0.002178857949762208,\n",
       " 0.009216992811773536,\n",
       " -0.013509571540335209,\n",
       " -0.01031782082649772,\n",
       " 0.011972320149510383,\n",
       " 0.014252142087965733,\n",
       " 0.013509571540335209,\n",
       " 2.1360605022285668e-05,\n",
       " 0.003898494909398934,\n",
       " 0.0253776701673954,\n",
       " 0.009282130448397598,\n",
       " -0.03389768905657205,\n",
       " 0.0052598741691113424,\n",
       " -0.005595333323688183,\n",
       " 0.006839464884043412,\n",
       " 0.013731040063650602,\n",
       " 0.007308456612794767,\n",
       " -0.029754927544171562,\n",
       " -0.041193119259629166,\n",
       " -0.027905015311286713,\n",
       " 0.01478627145334115,\n",
       " 0.0265371221482135,\n",
       " 0.03327236550980672,\n",
       " -0.005442259737923242,\n",
       " 0.01211562276381879,\n",
       " 0.01593269516177633,\n",
       " 0.0014981684363213335,\n",
       " 0.0258075798729659,\n",
       " -0.014825354407844642,\n",
       " 0.013952507655643357,\n",
       " 0.02279821565926295,\n",
       " 0.023631978525638104,\n",
       " -0.015502786387528467,\n",
       " -0.7045299890281258,\n",
       " -0.009373323698464867,\n",
       " 0.020948303426378097,\n",
       " -0.003592347505038393,\n",
       " 0.013008010527610504,\n",
       " 0.040672018166636674,\n",
       " 0.02694097717166343,\n",
       " 0.013809205041334947,\n",
       " -0.016049943093964167,\n",
       " 0.029650708815689285,\n",
       " 0.010194059223779738,\n",
       " 0.009405892051115578,\n",
       " 0.013561681835898986,\n",
       " -0.0005190665022744622,\n",
       " 0.006722216951855573,\n",
       " 0.00580051767067822,\n",
       " 0.001091871717745237,\n",
       " -0.0011960920760421315,\n",
       " -0.011939750865537033,\n",
       " -0.003849641449100228,\n",
       " -0.010194059223779738,\n",
       " 0.012838652299858888,\n",
       " -0.0220426168392495,\n",
       " 0.00598290323949012,\n",
       " 0.009725067495028383,\n",
       " -0.0024394089619197735,\n",
       " 0.011887640569973256,\n",
       " -0.011881126899443114,\n",
       " -0.01387434267795901,\n",
       " 0.004341431723199059,\n",
       " -0.01849912419149377,\n",
       " 0.01095617078300069,\n",
       " 0.003442530521707864,\n",
       " -0.013496543267952285,\n",
       " 0.06138582572863909,\n",
       " -0.007262859987761132,\n",
       " 0.0062532247574429,\n",
       " 0.015359483773220058,\n",
       " 0.005272901510171627,\n",
       " 0.036607420700597894,\n",
       " 0.0009029721873648699,\n",
       " -0.011496814750228885,\n",
       " 5.1779428644712756e-05,\n",
       " -0.010304793485437435,\n",
       " 0.015333428159776851,\n",
       " 0.01684462393715847,\n",
       " -0.008617725809774058,\n",
       " 0.003859412187726101,\n",
       " 0.005237075856594524,\n",
       " 0.00394734813686698,\n",
       " 0.006627766866523233,\n",
       " 0.00589171045508417,\n",
       " -0.01235663323004725,\n",
       " 0.026250516919596685,\n",
       " 0.004426110837074867,\n",
       " 3.0151657716610165e-05,\n",
       " 0.021508488405196723,\n",
       " -0.01229800926395333,\n",
       " 0.0023856704815541207,\n",
       " 0.015828474570648773,\n",
       " 0.0003460443348496415,\n",
       " -0.006451894968241475,\n",
       " -0.013196909766952546,\n",
       " -0.001261229829081523,\n",
       " -0.02546886341746267,\n",
       " 0.004517303621480818,\n",
       " -0.017196367733721987,\n",
       " -0.010005159984437694,\n",
       " -0.0051751950552355345,\n",
       " 0.0035956043403034643,\n",
       " -0.01360076385907984,\n",
       " 0.013757094745771171,\n",
       " -0.014799298794401434,\n",
       " -0.007282401465012878,\n",
       " 0.01900719794342598,\n",
       " 0.033011814963310473,\n",
       " 0.013796177700274663,\n",
       " -0.02539069937110096,\n",
       " -0.016935817187225737,\n",
       " 0.0006127020295445455,\n",
       " 0.0002334781615630075,\n",
       " -0.006419326149929444,\n",
       " -0.004852763241718978,\n",
       " -0.017938939212675146,\n",
       " 0.034939894967847586,\n",
       " -0.030640801637433133,\n",
       " -0.027983181220293696,\n",
       " 0.0028644329489313485,\n",
       " -0.0009550823665133171,\n",
       " 0.00840928462751895,\n",
       " 0.008520018889176646,\n",
       " 0.04669074659404258,\n",
       " 0.006240197416382615,\n",
       " -0.009125800493028904,\n",
       " 0.00692414399791922,\n",
       " 0.00023490304154339238,\n",
       " -0.030093643999674794,\n",
       " 0.019932154059868406,\n",
       " -0.005031891975265807,\n",
       " -0.02472629380115478,\n",
       " -0.0014509436264858227,\n",
       " -0.00810965112651921,\n",
       " -0.0029833092987517225,\n",
       " -0.0029409697418138186,\n",
       " 0.021860232201760237,\n",
       " 0.009366810027934724,\n",
       " -0.026198407555355546,\n",
       " 0.038457332933482746,\n",
       " 0.029129605860051512,\n",
       " -0.021469404519370593,\n",
       " -0.006077352859161142,\n",
       " 0.0016056457462986287,\n",
       " -0.011431677113604825,\n",
       " 0.012799569345355396,\n",
       " 0.0076732282160798864,\n",
       " -0.034210352692599984,\n",
       " -0.01672737600497063,\n",
       " 0.017170313051601417,\n",
       " 0.020505366379747314,\n",
       " -0.02826978831155579,\n",
       " -0.000491382995067703,\n",
       " -0.00042787365966084716,\n",
       " 0.02106555135856594,\n",
       " -0.01590664047965576,\n",
       " 0.0065007484285401805,\n",
       " 0.023423537343382997,\n",
       " -0.005787489863956616,\n",
       " 0.007262859987761132,\n",
       " -0.020036374650995958,\n",
       " 0.005513911510738765,\n",
       " 0.019580410263304888,\n",
       " -0.00932121340290109,\n",
       " 0.009972590700464344,\n",
       " -0.00932121340290109,\n",
       " 0.015724255842166496,\n",
       " -0.011874613228912971,\n",
       " 0.009972590700464344,\n",
       " -0.017365726892796238,\n",
       " -0.005608361130409787,\n",
       " -0.0017945452184713311,\n",
       " -0.0010251054306579803,\n",
       " 0.01955435558118432,\n",
       " -0.00838322994539838,\n",
       " -0.019684630854432443,\n",
       " -0.004745285815326353,\n",
       " -0.02068775287988185,\n",
       " -0.017027010437293006,\n",
       " -0.005859141636772139,\n",
       " -0.013157827743771692,\n",
       " 0.0013915053351603059,\n",
       " 0.0016032031198498255,\n",
       " 0.00926258943680717,\n",
       " -0.003992944761900615,\n",
       " 0.01989307203668755,\n",
       " 0.03553916010720179,\n",
       " 0.0001497150617093334,\n",
       " 0.004139504677135413,\n",
       " -0.016128109002971153,\n",
       " -0.028165567720428233,\n",
       " -0.010513234667692542,\n",
       " -0.009966077029934203,\n",
       " 0.03129217986631903,\n",
       " -0.013066634493704423,\n",
       " -0.005129598430201899,\n",
       " -0.008005430535391657,\n",
       " -0.024061888231208604,\n",
       " 0.003497897652536712,\n",
       " 0.008103137455989068,\n",
       " -0.004090651216836707,\n",
       " -0.036503201972115616,\n",
       " 0.021156744608633208,\n",
       " -0.016062972297669727,\n",
       " -0.022094728066135917,\n",
       " 0.013913425632462501,\n",
       " 0.015698199297400652,\n",
       " -0.00046125674499681066,\n",
       " -0.014043700905710626,\n",
       " 0.010943143441940405,\n",
       " 0.0040189999096825035,\n",
       " -0.03045841699994387,\n",
       " 0.02785290594704557,\n",
       " -0.0012123764851981469,\n",
       " -0.008239926399767334,\n",
       " 0.018994170602365697,\n",
       " 0.021795093633813538,\n",
       " 0.003543494044739687,\n",
       " 0.020296925197492207,\n",
       " 0.027644464764790464,\n",
       " -0.008708918128518688,\n",
       " 0.01150984209128917,\n",
       " 0.007210750157858674,\n",
       " 0.007901209944264102,\n",
       " -0.0295725429066823,\n",
       " 0.000430316315213483,\n",
       " 0.01269534968555048,\n",
       " 0.01758719541611163,\n",
       " 0.0168185692550379,\n",
       " -0.0041134495293535245,\n",
       " 0.008637266821364484,\n",
       " 0.02467418257426837,\n",
       " 0.025612166031771078,\n",
       " 0.007204236021667213,\n",
       " 0.03090135218392938,\n",
       " -0.021638763678444847,\n",
       " -0.013431405631328225,\n",
       " -0.009848829097746363,\n",
       " -0.0031347546997147874,\n",
       " -0.00507097446410798,\n",
       " 0.02213381008931677,\n",
       " 0.01320342343748269,\n",
       " 0.0008541188434814938,\n",
       " -0.013340213312583593,\n",
       " -0.00859167019633085,\n",
       " 0.006445381297711333,\n",
       " 0.019684630854432443,\n",
       " 0.02030995253855249,\n",
       " 0.0022000278446464897,\n",
       " 0.0065007484285401805,\n",
       " -0.016662239299669205,\n",
       " -0.008285523024800968,\n",
       " 0.0034164753739259752,\n",
       " -0.014213059133462241,\n",
       " 0.002657620649970095,\n",
       " -0.008174788763143273,\n",
       " 0.004445651848665294,\n",
       " 0.029494376997675313,\n",
       " 0.00835066066142503,\n",
       " 0.025755470508724763,\n",
       " 0.0035956043403034643,\n",
       " -0.007972861251418308,\n",
       " -0.0011578236796008963,\n",
       " 0.011946265467389814,\n",
       " -0.0023661290043023747,\n",
       " 0.00409716488736685,\n",
       " -0.008897818299183369,\n",
       " -0.007569007624952333,\n",
       " 0.006149004631976665,\n",
       " -0.02441363202777212,\n",
       " 0.02996336872642667,\n",
       " -0.020492339038687028,\n",
       " -0.004321890245947314,\n",
       " 0.02037509110649919,\n",
       " 0.029103551177930943,\n",
       " -0.02498684434765103,\n",
       " 0.012597642764953069,\n",
       " 0.019541328240124035,\n",
       " 0.0066538220143051215,\n",
       " 0.0017505772439008916,\n",
       " 0.025117119620899152,\n",
       " 0.022420417180578862,\n",
       " 0.0069501986800397896,\n",
       " 0.006852492225103697,\n",
       " -0.009138827834089189,\n",
       " 0.004566157081779524,\n",
       " 0.0052794151807017695,\n",
       " -0.016492880140594954,\n",
       " -0.0180431598038027,\n",
       " 0.01405672824677091,\n",
       " 0.006995795305073424,\n",
       " 0.02404886089014832,\n",
       " -0.014460582338898203,\n",
       " 0.018512151532554057,\n",
       " 0.010689106565974299,\n",
       " -0.011998374831630952,\n",
       " 0.007516897329388556,\n",
       " 0.00048812607249113454,\n",
       " -0.002602253519141247,\n",
       " -0.017782607394661178,\n",
       " 0.006969740157291535,\n",
       " -0.0024882624222184796,\n",
       " 0.008572129184740422,\n",
       " -0.0006298007057244936,\n",
       " 0.027019143080670417,\n",
       " -0.013822232382395232,\n",
       " 0.02484354173334262,\n",
       " 0.015659117274219796,\n",
       " 0.0038366141080399432,\n",
       " 0.007901209944264102,\n",
       " -0.01773049803042004,\n",
       " -0.009451488676149214,\n",
       " -0.023697117093584803,\n",
       " -0.03298576028118991,\n",
       " 0.01014194892821596,\n",
       " 0.011457731795725394,\n",
       " -0.009269103107337313,\n",
       " -0.007810017159858153,\n",
       " -0.04361624194974765,\n",
       " -8.707086682551071e-05,\n",
       " -0.00023754926385201135,\n",
       " 0.021534543087317292,\n",
       " -0.0060350135350538976,\n",
       " 0.004956983367185213,\n",
       " 0.014538748247905187,\n",
       " -0.013835259723455517,\n",
       " -0.013770122086831456,\n",
       " 0.011418648841221901,\n",
       " 0.03796228652261082,\n",
       " -0.0038887241707730607,\n",
       " -0.011360024875127982,\n",
       " -8.340686166868263e-05,\n",
       " 0.007438731886042891,\n",
       " 0.01235663323004725,\n",
       " 0.007132584714513009,\n",
       " -0.01496865702215305,\n",
       " -0.00582657235279879,\n",
       " 0.012004889433483733,\n",
       " -0.01631049550310569,\n",
       " -0.019163527898794674,\n",
       " -0.00680038192953992,\n",
       " -0.0028318641306193174,\n",
       " -0.003276429362051979,\n",
       " 0.010311307155967576,\n",
       " -0.00291491482686259,\n",
       " 0.006859005895633839,\n",
       " 0.003891981006038132,\n",
       " 0.020922248744257528,\n",
       " -0.01138608048857119,\n",
       " -0.00771231070492206,\n",
       " 0.011158098294725655,\n",
       " -0.023084820887879765,\n",
       " -0.007595062772734221,\n",
       " -0.019254721148861943,\n",
       " -0.010037728337088407,\n",
       " 0.0076471730682979985,\n",
       " 0.07769632123174479,\n",
       " 0.025651249917597208,\n",
       " -0.01153589677340974,\n",
       " -0.0044847348031687865,\n",
       " 0.00971855382449824,\n",
       " 0.024400604686711836,\n",
       " -0.0029442268099095495,\n",
       " -0.014877463772085781,\n",
       " -0.0008964584004193978,\n",
       " -0.016558018708541653,\n",
       " 0.005171938219970463,\n",
       " -0.010760757873128505,\n",
       " -0.016714348663910344,\n",
       " 0.01758719541611163,\n",
       " 0.011457731795725394,\n",
       " -0.009790205131652444,\n",
       " 0.008520018889176646,\n",
       " -0.006657078849570193,\n",
       " 0.008930386651834082,\n",
       " 0.008936900322364223,\n",
       " 0.0017424350393228838,\n",
       " -0.009373323698464867,\n",
       " 0.008272495683740683,\n",
       " 0.020336009083318337,\n",
       " 0.020153622583183796,\n",
       " -0.00646817961022815,\n",
       " 0.009770664120062018,\n",
       " 0.02699308653590457,\n",
       " -0.002830235712986782,\n",
       " -0.006898088850137331,\n",
       " -0.004022256744947574,\n",
       " 0.004833221764467232,\n",
       " 0.006331390200788566,\n",
       " 0.01542462140984412,\n",
       " 0.016948844528286024,\n",
       " 0.011229749601879859,\n",
       " -0.016662239299669205,\n",
       " 0.016062972297669727,\n",
       " 0.01545067609196469,\n",
       " -0.0032780577796845145,\n",
       " 0.00947754428959242,\n",
       " 0.00598290323949012,\n",
       " 0.009835801756686078,\n",
       " -0.016922789846165454,\n",
       " 0.003276429362051979,\n",
       " -0.012968927573107011,\n",
       " -0.012708377026610766,\n",
       " 0.01943710764899648,\n",
       " 0.0006806895716485392,\n",
       " 0.0011912068231445248,\n",
       " 0.019632521490191304,\n",
       " -0.005041662481061021,\n",
       " -0.02261582915912841,\n",
       " -0.016623155413843075,\n",
       " 0.0022244545747958423,\n",
       " 0.01478627145334115,\n",
       " -0.013704984450207394,\n",
       " -0.010168004541659168,\n",
       " -0.010409014076564988,\n",
       " 0.011138556351812589,\n",
       " -0.011920209853946605,\n",
       " -0.014395444702274142,\n",
       " 0.0005276158694682687,\n",
       " 0.009490571630652705,\n",
       " -0.03530466424282611,\n",
       " -0.03866577411573786,\n",
       " -0.00990093939331014,\n",
       " -0.0008875019870251223,\n",
       " -0.009119285891176124,\n",
       " 0.0070348777939155975,\n",
       " -0.007132584714513009,\n",
       " -0.0015901755459588813,\n",
       " -0.0015396937844429695,\n",
       " -0.002511060501904637,\n",
       " 0.001885738119292611,\n",
       " 0.02171692958745183,\n",
       " 0.006872033702355443,\n",
       " -0.014538748247905187,\n",
       " 0.028921164677796405,\n",
       " 0.008917359310773797,\n",
       " -0.0020697523385677066,\n",
       " -0.027592355400549325,\n",
       " 0.013887370019019294,\n",
       " -0.014017645292267417,\n",
       " -0.00121481922806228,\n",
       " -2.7276437359426325e-05,\n",
       " -0.01196580647898024,\n",
       " 0.002071380756200242,\n",
       " -0.0025582855445708073,\n",
       " 0.012591129094422926,\n",
       " 0.024127026799155304,\n",
       " 0.0037421642555382625,\n",
       " 0.005914508301939668,\n",
       " 0.007601576443264363,\n",
       " 0.0036965678633352874,\n",
       " -0.01159452073950366,\n",
       " 0.012897276265952808,\n",
       " -0.002203284679911561,\n",
       " -0.014903519385528988,\n",
       " -0.007998916864861514,\n",
       " 0.0022570233931078734,\n",
       " -0.01214819204779214,\n",
       " -0.010044242007618548,\n",
       " -0.013483515926892,\n",
       " 0.014642967907710103,\n",
       " 0.0006562628997068511,\n",
       " 0.0027716117468928624,\n",
       " 0.013379295335764447,\n",
       " 0.0017684901871047724,\n",
       " 0.0024833771693208726,\n",
       " 0.022185921316203186,\n",
       " -0.02258977447700784,\n",
       " 0.0074191908744524636,\n",
       " -0.007126071043982866,\n",
       " 0.0005805402574329837,\n",
       " 0.019189584443560517,\n",
       " -0.0030321627590504286,\n",
       " 0.0295725429066823,\n",
       " -0.03144851168433299,\n",
       " -0.01861637212368161,\n",
       " 0.007119556907791405,\n",
       " -0.033506865099472954,\n",
       " 0.013665901495703901,\n",
       " 0.007555980283892048,\n",
       " 0.0029474836451746206,\n",
       " -0.003768219403320151,\n",
       " 0.01218076133176549,\n",
       " -0.011789934580698483,\n",
       " 0.011379566818041047,\n",
       " 0.005513911510738765,\n",
       " 0.0007694397878133509,\n",
       " 0.029181715224292654,\n",
       " -0.005657214590708492,\n",
       " -0.020166649924244082,\n",
       " -0.026967031853784,\n",
       " -0.003647714403036582,\n",
       " -0.0062825367404898596,\n",
       " -0.0044847348031687865,\n",
       " -0.02632868282860367,\n",
       " -0.03368924787431694,\n",
       " -0.03457512196757851,\n",
       " -0.008962955935807431,\n",
       " 0.010265710530933942,\n",
       " -0.02785290594704557,\n",
       " -0.018863895329117572,\n",
       " -0.0507553403347908,\n",
       " -0.005468314885705131,\n",
       " 0.007451759692764494,\n",
       " -0.0005662913703176378,\n",
       " 0.00242963845612456,\n",
       " -0.011431677113604825,\n",
       " 0.010799840827631996,\n",
       " -0.025364642826335115,\n",
       " -0.03358502914583466,\n",
       " -0.010330848167558004,\n",
       " -0.028816944086668853,\n",
       " -0.00692414399791922,\n",
       " 0.005644186783986889,\n",
       " 0.0353567773323578,\n",
       " 0.02106555135856594,\n",
       " 0.01053277567928297,\n",
       " 0.004514046786215747,\n",
       " 0.013333699642053451,\n",
       " -0.004667120371980687,\n",
       " 0.018381876259305933,\n",
       " 0.0070348777939155975,\n",
       " 0.002911657758766859,\n",
       " -0.00680038192953992,\n",
       " -0.006943685009509647,\n",
       " 0.012428284537201453,\n",
       " 0.012063513399577652,\n",
       " 0.035513105425081216,\n",
       " -0.0021023211568797374,\n",
       " -0.0025452579706798633,\n",
       " 0.0074647870338247786,\n",
       " 0.015072877613280604,\n",
       " -0.003455558095598808,\n",
       " -0.010005159984437694,\n",
       " -0.0055073973745473044,\n",
       " -0.020127567901063226,\n",
       " 0.0032813146149495856,\n",
       " -0.007829558637109898,\n",
       " -0.0044098261950881925,\n",
       " 0.017027010437293006,\n",
       " 0.01238920158269796,\n",
       " -0.012219843354946344,\n",
       " 0.04273037158177663,\n",
       " 0.013457461244771431,\n",
       " 0.030771076910681254,\n",
       " 0.0033513377373019138,\n",
       " 0.025312533462093976,\n",
       " -0.0048495059407925875,\n",
       " 0.025403726712161245,\n",
       " 0.016857651278218755,\n",
       " 0.013783149427891741,\n",
       " 0.027149418353918542,\n",
       " -0.01384828799583844,\n",
       " -0.029728872862050993,\n",
       " -0.010930116100880119,\n",
       " 0.01253901879885915,\n",
       " 0.00065667006232265,\n",
       " 0.020791973471009407,\n",
       " -0.025911800464093453,\n",
       " 0.005725609062597625,\n",
       " -0.005875425813097495,\n",
       " 0.03082318813756767,\n",
       " -0.0027764969997904694,\n",
       " -0.010239655848813372,\n",
       " -0.009184424459122823,\n",
       " -0.0016146021596929044,\n",
       " -0.006067582353365928,\n",
       " -0.020075456674176814,\n",
       " -0.018394903600366216,\n",
       " -0.013744067404710887,\n",
       " 0.00816827509261313,\n",
       " -0.01515104259096495,\n",
       " -0.013170855084831977,\n",
       " 0.03629476078986051,\n",
       " -0.021247937858700477,\n",
       " -0.01296241390257687,\n",
       " -0.011829016603879337,\n",
       " -0.0024638356920691266,\n",
       " 0.025677304599717777,\n",
       " -0.0036639990450232566,\n",
       " 0.017873800644728446,\n",
       " 0.016662239299669205,\n",
       " -0.012968927573107011,\n",
       " -0.02510409227983887,\n",
       " -0.0036086319141944083,\n",
       " -0.004953726531920142,\n",
       " -0.00789469627373396,\n",
       " 0.028712723495541298,\n",
       " -0.0017684901871047724,\n",
       " 0.013900397360079579,\n",
       " -0.023918585616900197,\n",
       " 0.0022733078022638886,\n",
       " -0.004435881342870081,\n",
       " -0.009451488676149214,\n",
       " -0.013034065209731074,\n",
       " 0.021352156587182754,\n",
       " 0.01812132385016441,\n",
       " -0.0070739607484190895,\n",
       " -0.026042075737341578,\n",
       " 0.00385615535246103,\n",
       " -0.02030995253855249,\n",
       " 0.016036915752903884,\n",
       " 0.005595333323688183,\n",
       " -0.008285523024800968,\n",
       " -0.010676078293591377,\n",
       " 0.004093908052101779,\n",
       " -0.014004617951207133,\n",
       " 0.014460582338898203,\n",
       " -0.017469947483923793,\n",
       " 0.014278196770086302,\n",
       " 0.0303020851819299,\n",
       " -0.010949657112470547,\n",
       " -0.009392864710055293,\n",
       " 0.0051165710891416145,\n",
       " -0.002489890839851015,\n",
       " 0.009966077029934203,\n",
       " 0.0075494661477005865,\n",
       " 0.015072877613280604,\n",
       " -0.009125800493028904,\n",
       " 0.005031891975265807,\n",
       " -0.0012864707680471437,\n",
       " -0.010930116100880119,\n",
       " -0.030406305773057453,\n",
       " -0.005627902607661533,\n",
       " 0.006937171338979505,\n",
       " 0.027097307127032125,\n",
       " -0.016505907481655237,\n",
       " 0.01138608048857119,\n",
       " 0.0067026754746038275,\n",
       " 0.006611482690197877,\n",
       " 0.01642774343529353,\n",
       " -0.0030712452478926016,\n",
       " -0.013809205041334947,\n",
       " -0.023162986796886748,\n",
       " -0.014538748247905187,\n",
       " -0.004413083030353264,\n",
       " 0.0433556914032514,\n",
       " -0.0019606464945425457,\n",
       " -0.018420958282486785,\n",
       " -0.00762111792051611,\n",
       " -0.025025926370831883,\n",
       " -0.02959859758880287,\n",
       " -0.03736301765796607,\n",
       " 0.0028465201221427976,\n",
       " 0.006360702183835525,\n",
       " -0.02419216350445673,\n",
       " -0.017456920142863507,\n",
       " -0.01763930478035277,\n",
       " 0.006341160706583779,\n",
       " 0.018590315578915766,\n",
       " 0.007425704544982606,\n",
       " -0.02320207068271288,\n",
       " 0.019580410263304888,\n",
       " 0.01812132385016441,\n",
       " -0.015359483773220058,\n",
       " 0.007230291169449101,\n",
       " 0.002890488096713237,\n",
       " -0.01145121812519525,\n",
       " -0.03869182879785842,\n",
       " 0.017626277439292487,\n",
       " 0.0066896476678822234,\n",
       " -0.020049401992056244,\n",
       " 0.0025403727177822563,\n",
       " -0.00926258943680717,\n",
       " -0.018668481487922748,\n",
       " 0.0017391782040578126,\n",
       " 0.005338039146795689,\n",
       " 0.011366538545658124,\n",
       " 0.003291085353575459,\n",
       " 0.003186864762447905,\n",
       " -0.006412812479399302,\n",
       " 0.013731040063650602,\n",
       " -0.0003627359066214557,\n",
       " 0.004328403916477456,\n",
       " -0.012493422173825515,\n",
       " 0.008787084037525674,\n",
       " -0.0019020225284486264,\n",
       " 0.009412405721645721,\n",
       " -0.011262318885853209,\n",
       " -0.01369195710914711,\n",
       " 0.016558018708541653,\n",
       " -0.01423911381558281,\n",
       " 0.017144258369480844,\n",
       " 0.011588007068973517,\n",
       " -0.019906099377747836,\n",
       " 0.008155247751552845,\n",
       " 0.010311307155967576,\n",
       " 0.008142219479169922,\n",
       " -0.008265982013210542,\n",
       " 0.0006819109430806058,\n",
       " 0.0006245082902110881,\n",
       " -0.015841503774354334,\n",
       " -0.01898114326130541,\n",
       " -0.00582982965372518,\n",
       " 0.014838381748904927,\n",
       " -0.005956848091708232,\n",
       " 0.014525719975522265,\n",
       " 0.001822228783885755,\n",
       " -0.00992699407543071,\n",
       " 0.021352156587182754,\n",
       " -0.0007030806633418928,\n",
       " -0.00856561551421028,\n",
       " 0.008923872981303939,\n",
       " -0.008292036695331111,\n",
       " -0.009366810027934724,\n",
       " -0.0012880991856796793,\n",
       " -0.014799298794401434,\n",
       " 0.02425730207240343,\n",
       " 0.028009235902414265,\n",
       " -0.015398565796400912,\n",
       " -0.014616913225589534,\n",
       " 0.004771340963108241,\n",
       " -0.009601305892310402,\n",
       " 0.0026592490676026308,\n",
       " -0.008910845640243654,\n",
       " 0.004233954296806434,\n",
       " 0.019814906127680568,\n",
       " 0.018772702079050303,\n",
       " 0.008487449605203297,\n",
       " 0.017352699551735955,\n",
       " -0.01433030706565008,\n",
       " 0.010689106565974299,\n",
       " -0.020570504947694013,\n",
       " -0.018147380394930256,\n",
       " 0.008363688002485315,\n",
       " 0.0029979652902752023,\n",
       " 0.013952507655643357,\n",
       " -0.016036915752903884,\n",
       " -0.017482974824984076,\n",
       " -0.025156201644080008,\n",
       " 0.017079119801534145,\n",
       " -0.004774597798373312,\n",
       " -0.02176903895169297,\n",
       " 0.012226357025476487,\n",
       " -0.013796177700274663,\n",
       " -0.009770664120062018,\n",
       " -0.012838652299858888,\n",
       " 0.012187275002295633,\n",
       " -0.021834177519639668,\n",
       " -0.006793868259009778,\n",
       " 0.03665953006483903,\n",
       " -0.016935817187225737,\n",
       " -0.011210208590289431,\n",
       " 0.009464516017209499,\n",
       " -0.03285548687058706,\n",
       " 0.009236533823363964,\n",
       " -0.02064866899405572,\n",
       " -0.003641200732506439,\n",
       " -0.003771476238585222,\n",
       " 0.008370201673015458,\n",
       " -0.0016056457462986287,\n",
       " 0.005771205221969941,\n",
       " 0.010858464793725915,\n",
       " -0.02429638409558428,\n",
       " 0.018342792373479803,\n",
       " 0.010715161248094868,\n",
       " -0.009529654585156198,\n",
       " 0.035695491925215754,\n",
       " -0.006859005895633839,\n",
       " 0.0026315655021882066,\n",
       " -0.017509029507104645,\n",
       " 0.011939750865537033,\n",
       " -0.00601221522253708,\n",
       " -0.011483786477845963,\n",
       " 0.022355278612632163,\n",
       " -0.01384828799583844,\n",
       " -0.014082783860214117,\n",
       " -0.03090135218392938,\n",
       " -0.013926452973522786,\n",
       " -0.028530338858052035,\n",
       " -0.0028742036875572213,\n",
       " -0.019241693807801656,\n",
       " -0.01676645989079676,\n",
       " -0.017691416007239186,\n",
       " 0.019958208741988975,\n",
       " 0.002310762106304186,\n",
       " -0.019046279966606836,\n",
       " -0.001425702687520202,\n",
       " -0.018694536170043317,\n",
       " -0.021430322496189737,\n",
       " -0.003227575901753273,\n",
       " -0.016154163685091722,\n",
       " 0.020205731947424938,\n",
       " 0.014173976178958748,\n",
       " 0.0016756688686509569,\n",
       " 0.014069755587831195,\n",
       " -0.018251600986057808,\n",
       " -0.018942061238124558,\n",
       " 0.0012278468019532242,\n",
       " 0.012916817277543235,\n",
       " -0.004813680287215486,\n",
       " 0.02395766764008105,\n",
       " 0.22553297922039042,\n",
       " -0.011737824285134705,\n",
       " -0.0110538777035981,\n",
       " 0.04825405359831061,\n",
       " 0.013757094745771171,\n",
       " 0.013639846813583332,\n",
       " 0.02638079219284481,\n",
       " 0.009282130448397598,\n",
       " -0.006552858724103958,\n",
       " 0.02149546106413644,\n",
       " -0.017378754233856524,\n",
       " 0.003647714403036582,\n",
       " -0.011242776942940144,\n",
       " 0.011197181249229146,\n",
       " 0.009640387915491256,\n",
       " -0.0022179406714350407,\n",
       " -0.03288154155270763,\n",
       " -0.018251600986057808,\n",
       " -0.02322812536483345,\n",
       " -0.022733077091316247,\n",
       " -0.011216722260819574,\n",
       " -0.007777448341546121,\n",
       " -0.02601602105522101,\n",
       " 0.012988469516020076,\n",
       " 0.038639719433617284,\n",
       " 8.009908742088795e-05,\n",
       " -0.01341837829026794,\n",
       " 0.010161490871129025,\n",
       " 0.012851679640919173,\n",
       " -0.0010104494391345003,\n",
       " -0.013809205041334947,\n",
       " -0.03223016332382173,\n",
       " 0.0086242394803042,\n",
       " 0.019267748489922226,\n",
       " -0.00028395992307891915,\n",
       " -0.003181979509550298,\n",
       " 0.008923872981303939,\n",
       " 0.012304522934483472,\n",
       " 0.018290683009238664,\n",
       " 0.0002465057063501193,\n",
       " -0.014669023521153311,\n",
       " 0.0008655179997399025,\n",
       " 0.002763469425899525,\n",
       " -0.02595088248727431,\n",
       " -0.009731581165558525,\n",
       " 0.0014240742698876665,\n",
       " ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "embedder.embed_query(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "vector = embedder.embed_documents([\n",
    "    \"hi\",\n",
    "    \"how\",\n",
    "    \"are\",\n",
    "    \"you\",\n",
    "])\n",
    "\n",
    "print(len(vector), len(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1499, which is longer than the specified 600\n",
      "Created a chunk of size 1425, which is longer than the specified 600\n",
      "Created a chunk of size 1487, which is longer than the specified 600\n",
      "Created a chunk of size 1498, which is longer than the specified 600\n",
      "Created a chunk of size 1414, which is longer than the specified 600\n",
      "Created a chunk of size 1495, which is longer than the specified 600\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1499, which is longer than the specified 600\n",
      "Created a chunk of size 1425, which is longer than the specified 600\n",
      "Created a chunk of size 1487, which is longer than the specified 600\n",
      "Created a chunk of size 1498, which is longer than the specified 600\n",
      "Created a chunk of size 1414, which is longer than the specified 600\n",
      "Created a chunk of size 1495, which is longer than the specified 600\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import  LocalFileStore\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "#vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "vectorstore = Chroma.from_documents(docs, cached_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1499, which is longer than the specified 600\n",
      "Created a chunk of size 1425, which is longer than the specified 600\n",
      "Created a chunk of size 1487, which is longer than the specified 600\n",
      "Created a chunk of size 1498, which is longer than the specified 600\n",
      "Created a chunk of size 1414, which is longer than the specified 600\n",
      "Created a chunk of size 1495, which is longer than the specified 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'옮긴이는 소설이 편지의 형식을 가지고 있다고 설명하고 있습니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import  LocalFileStore\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size = 600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "#vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "vectorstore = Chroma.from_documents(docs, cached_embeddings)\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    ")\n",
    "\n",
    "chain.run(\"옮긴이가 소설이 무슨 형식이라고 하고 있니?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3144, which is longer than the specified 600\n",
      "Created a chunk of size 886, which is longer than the specified 600\n",
      "Created a chunk of size 2976, which is longer than the specified 600\n",
      "Created a chunk of size 3095, which is longer than the specified 600\n",
      "Created a chunk of size 3096, which is longer than the specified 600\n",
      "Created a chunk of size 2927, which is longer than the specified 600\n",
      "Created a chunk of size 3158, which is longer than the specified 600\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\2984330158.py\", line 40, in <module>\n",
      "    chain.invoke(\"키다리아저씨 스미스씨를 묘사해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1204, in invoke\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\2984330158.py\", line 40, in <module>\n",
      "    chain.invoke(\"키다리아저씨 스미스씨를 묘사해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1693, in invoke\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\retriever.py\", line 112, in invoke\n",
      "    return self.get_relevant_documents(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\retriever.py\", line 186, in get_relevant_documents\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\passthrough.py\", line 192, in invoke\n",
      "    return self._call_with_config(identity, input, config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\2984330158.py\", line 40, in <module>\n",
      "    chain.invoke(\"키다리아저씨 스미스씨를 묘사해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\prompt_template.py\", line 60, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\2984330158.py\", line 40, in <module>\n",
      "    chain.invoke(\"키다리아저씨 스미스씨를 묘사해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 142, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 459, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 319, in generate\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='키다리 아저씨인 스미스 씨는 고아들을 대학에 보내주는 친절한 평의원으로 묘사됩니다.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/키다리아저씨2장.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"너는 훌륭한 조수야, 대답은 오직 주어진 context에 맞게 해줘. 만약 정답을 모르면 지어내지 말고 모른다고 해.:\\n\\n{context}\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = {\"context\": retriver, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "\n",
    "chain.invoke(\"키다리아저씨 스미스씨를 묘사해줘.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 79, in <module>\n",
      "    chain.invoke(\"주인공의 성격을 말해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1204, in invoke\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 79, in <module>\n",
      "    chain.invoke(\"주인공의 성격을 말해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1693, in invoke\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1204, in invoke\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\passthrough.py\", line 192, in invoke\n",
      "    return self._call_with_config(identity, input, config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1693, in invoke\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\retriever.py\", line 112, in invoke\n",
      "    return self.get_relevant_documents(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\retriever.py\", line 186, in get_relevant_documents\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\passthrough.py\", line 192, in invoke\n",
      "    return self._call_with_config(identity, input, config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1204, in invoke\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\prompt_template.py\", line 60, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 142, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 459, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 319, in generate\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [Document(page_content='(리펫 원장의 대사→) “너도, 방금 막 나가신 신사 분을 목격했겠지?” (제루샤의 대사→) “등만 본 걸요.” “그는 우리 평의원들 중에서도 가장 재력과 사회적 영향력을 갖춘 사람이란다, 지금까지 상당한 액수의 금액을 고아원 기금으로 기부도 하셨고 말이다. 엄밀히 말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의 조건으로 내거셨거든.” 이 부분에서 제루샤의 눈이 살짝 휘둥그레졌다. 별난 평의원에 관해 얘기하려 자신을 원장실로 부르는 건 원장의 평소 행동이 아니었기 때문이다. “이 신사 분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리 벤톤’과 ‘헨리 프리즈’ 말이다. (두 소년 모두 몰라도 되는 이름임. 다시 안 나옴) 그 애들은 미스터… 이 평의원께서 후원해 주셨고, 그 애들도 열심히 노력한 결과 나름 성공할 수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두 소년들만 초점이 맞추어져 있었단다. 고아원에 있는 여자애들에겐 전혀 관심을 표하시지 않으셨지. 여자애들이 후원을 받을만한가는 둘째치고서라도 말이다. 그래 내가 네(제루샤)게 말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.” “네, 원장님.”라며 제루샤가 옹알거렸다. 이 부분에서 자신에게 뭔가 대답을 요구하는 것 같았기 때문이다. “오늘 정기 모임에서는, 네(여주인공인 제루샤) 장래에 관한 얘기가 꺼내어졌다.” 리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에 얘기를 천천히 다시 시작했다. “너도 알다시피, 대개의 경우에는, 16살이 되면(제루샤는 현재 17살임) 여기에 계속 있을 수 없다. 하지만 넌 예외였다. 네가 14살에 고아원 학교를 마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건 아니었다만. 결국 내 주장에 따라 넌 근처 마을에 있는 고등학교에 여기에 있으면서 다니는 게 허락되었고, 이제 그 마저도 다 끝마쳤다. 물론 그 이상의 교육(대학교)을 고아원에서 지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱 말이다.” 지난 2년 동안 제루샤가 열심히 생활했다는 사실과 고아원의 편의를 받아 첫 번째 학업 과정과 두 번째 학원 과정을 마친 사실과 아이들을 돌보며 고아원에 머물고 있는 현재의 사정을, 리펫 원장은 쭉 훑어나갔다. “이미 말한 대로, 평의원 회의에서 네 장래에 대한 안건이 상정되어 네 경력이 화제로 다루어졌단다… 아주 철저히 말이다.” 리펫(여자이름) 원장은 독(항아리) 안에 든 이 죄수의 유무죄를 따지려는 듯 비난하는 눈초리로 찬찬히 살폈다. 그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의 성적표에서 유달리 참담했던 과목의 성적을 기억해냈기 때문은 아니었다. “물론 네게 줄 수 있는 배려들 중 하나는 네가 일을 시작할 수 있는 알맞은 직책을 찾아주는 것일 수도 있다.', metadata={'source': './files/키다리아저씨2장.txt'}), Document(page_content='(리펫 원장의 대사→) “너도, 방금 막 나가신 신사 분을 목격했겠지?” (제루샤의 대사→) “등만 본 걸요.” “그는 우리 평의원들 중에서도 가장 재력과 사회적 영향력을 갖춘 사람이란다, 지금까지 상당한 액수의 금액을 고아원 기금으로 기부도 하셨고 말이다. 엄밀히 말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의 조건으로 내거셨거든.” 이 부분에서 제루샤의 눈이 살짝 휘둥그레졌다. 별난 평의원에 관해 얘기하려 자신을 원장실로 부르는 건 원장의 평소 행동이 아니었기 때문이다. “이 신사 분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리 벤톤’과 ‘헨리 프리즈’ 말이다. (두 소년 모두 몰라도 되는 이름임. 다시 안 나옴) 그 애들은 미스터… 이 평의원께서 후원해 주셨고, 그 애들도 열심히 노력한 결과 나름 성공할 수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두 소년들만 초점이 맞추어져 있었단다. 고아원에 있는 여자애들에겐 전혀 관심을 표하시지 않으셨지. 여자애들이 후원을 받을만한가는 둘째치고서라도 말이다. 그래 내가 네(제루샤)게 말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.” “네, 원장님.”라며 제루샤가 옹알거렸다. 이 부분에서 자신에게 뭔가 대답을 요구하는 것 같았기 때문이다. “오늘 정기 모임에서는, 네(여주인공인 제루샤) 장래에 관한 얘기가 꺼내어졌다.” 리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에 얘기를 천천히 다시 시작했다. “너도 알다시피, 대개의 경우에는, 16살이 되면(제루샤는 현재 17살임) 여기에 계속 있을 수 없다. 하지만 넌 예외였다. 네가 14살에 고아원 학교를 마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건 아니었다만. 결국 내 주장에 따라 넌 근처 마을에 있는 고등학교에 여기에 있으면서 다니는 게 허락되었고, 이제 그 마저도 다 끝마쳤다. 물론 그 이상의 교육(대학교)을 고아원에서 지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱 말이다.” 지난 2년 동안 제루샤가 열심히 생활했다는 사실과 고아원의 편의를 받아 첫 번째 학업 과정과 두 번째 학원 과정을 마친 사실과 아이들을 돌보며 고아원에 머물고 있는 현재의 사정을, 리펫 원장은 쭉 훑어나갔다. “이미 말한 대로, 평의원 회의에서 네 장래에 대한 안건이 상정되어 네 경력이 화제로 다루어졌단다… 아주 철저히 말이다.” 리펫(여자이름) 원장은 독(항아리) 안에 든 이 죄수의 유무죄를 따지려는 듯 비난하는 눈초리로 찬찬히 살폈다. 그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의 성적표에서 유달리 참담했던 과목의 성적을 기억해냈기 때문은 아니었다. “물론 네게 줄 수 있는 배려들 중 하나는 네가 일을 시작할 수 있는 알맞은 직책을 찾아주는 것일 수도 있다.', metadata={'source': './files/키다리아저씨2장.txt'}), Document(page_content='(리펫 원장의 대사→) “너도, 방금 막 나가신 신사 분을 목격했겠지?” (제루샤의 대사→) “등만 본 걸요.” “그는 우리 평의원들 중에서도 가장 재력과 사회적 영향력을 갖춘 사람이란다, 지금까지 상당한 액수의 금액을 고아원 기금으로 기부도 하셨고 말이다. 엄밀히 말해 내가 그 분의 성함을 말할 권리는 없다. 그가 알려지지 않은 상태로 남기를 기부의 조건으로 내거셨거든.” 이 부분에서 제루샤의 눈이 살짝 휘둥그레졌다. 별난 평의원에 관해 얘기하려 자신을 원장실로 부르는 건 원장의 평소 행동이 아니었기 때문이다. “이 신사 분께서는 우리의 소년들 중 몇 명에게도 관심을 표하고 계신단다. 너도 기억하지? ‘찰리 벤톤’과 ‘헨리 프리즈’ 말이다. (두 소년 모두 몰라도 되는 이름임. 다시 안 나옴) 그 애들은 미스터… 이 평의원께서 후원해 주셨고, 그 애들도 열심히 노력한 결과 나름 성공할 수 있었지. 그 신사분이 바란 건 하나도 없었단다. 지금까지 그의 자선활동들은 모두 소년들만 초점이 맞추어져 있었단다. 고아원에 있는 여자애들에겐 전혀 관심을 표하시지 않으셨지. 여자애들이 후원을 받을만한가는 둘째치고서라도 말이다. 그래 내가 네(제루샤)게 말할 수 있는 건 적어도 지금까지는 여자애들에게 전혀 관심이 없어셨다는 것이다.” “네, 원장님.”라며 제루샤가 옹알거렸다. 이 부분에서 자신에게 뭔가 대답을 요구하는 것 같았기 때문이다. “오늘 정기 모임에서는, 네(여주인공인 제루샤) 장래에 관한 얘기가 꺼내어졌다.” 리펫 원장은 잠시 뜸을 들인 다음 누가 보더라도 제루샤가 긴장했을 게 뻔했기 때문에 얘기를 천천히 다시 시작했다. “너도 알다시피, 대개의 경우에는, 16살이 되면(제루샤는 현재 17살임) 여기에 계속 있을 수 없다. 하지만 넌 예외였다. 네가 14살에 고아원 학교를 마쳤을 때, 네 학업 성적이 워낙에 좋았기 때문이다. 물론 모든 과목이 다 좋은 건 아니었다만. 결국 내 주장에 따라 넌 근처 마을에 있는 고등학교에 여기에 있으면서 다니는 게 허락되었고, 이제 그 마저도 다 끝마쳤다. 물론 그 이상의 교육(대학교)을 고아원에서 지원해줄 순 없단다. 넌 이미 다른 아이들보다 2년이나 더 교육을 받은 경우이니 더더욱 말이다.” 지난 2년 동안 제루샤가 열심히 생활했다는 사실과 고아원의 편의를 받아 첫 번째 학업 과정과 두 번째 학원 과정을 마친 사실과 아이들을 돌보며 고아원에 머물고 있는 현재의 사정을, 리펫 원장은 쭉 훑어나갔다. “이미 말한 대로, 평의원 회의에서 네 장래에 대한 안건이 상정되어 네 경력이 화제로 다루어졌단다… 아주 철저히 말이다.” 리펫(여자이름) 원장은 독(항아리) 안에 든 이 죄수의 유무죄를 따지려는 듯 비난하는 눈초리로 찬찬히 살폈다. 그건 리펫 원장의 평소 버릇이었으며, 특별히 평의회 회의 때 제출되었던 제루샤의 성적표에서 유달리 참담했던 과목의 성적을 기억해냈기 때문은 아니었다. “물론 네게 줄 수 있는 배려들 중 하나는 네가 일을 시작할 수 있는 알맞은 직책을 찾아주는 것일 수도 있다.', metadata={'source': './files/키다리아저씨2장.txt'}), Document(page_content='하긴 뭐 하루 온종일 소방차를 끄는 말이 된 느낌이기도해요. :) (갑자기 종이 울리자) 거봐요 종이 울리네요! 어 불 꺼졌다. 그럼 안뇽. 참 학교규정 한번 잘 따르는 학생이라 생각했죠? ㅋㅋ 이게 다 〈존 그리어 고아원〉(여주인공이 나온 고아원이름)에서 몸에 밴 습관 때문이에요.\\n\\n당신을 너무도 존경하는,\\n\\n제루샤 에벗(여주인공이름)이.\\n\\n(2장 끝. 즉 여주인공이 키다리 아저씨에게 1번째로 보낸 편지의 전체 끝)', metadata={'source': './files/키다리아저씨2장.txt'})], 'question': '주인공의 성격을 말해줘.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1204, in invoke\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\prompt_template.py\", line 60, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 142, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 459, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 319, in generate\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1204, in invoke\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\prompt_template.py\", line 60, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 142, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 459, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 319, in generate\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1204, in invoke\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\prompt_template.py\", line 60, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2294, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 715, in _call_with_config\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 2227, in _invoke\n",
      "    output = call_func_with_variable_args(self.func, input, config, run_manager)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 308, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 46, in map_docs\n",
      "    return \"\\n\\n\".join(\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 47, in <genexpr>\n",
      "    map_doc_chain.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 142, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 459, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 319, in generate\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 79, in <module>\n",
      "    chain.invoke(\"주인공의 성격을 말해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\prompt_template.py\", line 60, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 707, in _call_with_config\n",
      "    callback_manager = get_callback_manager_for_config(config)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\config.py\", line 363, in get_callback_manager_for_config\n",
      "    return CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2072, in _configure\n",
      "    handler = LangChainTracer(project_name=tracer_project)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 97, in __init__\n",
      "    self.client = client or get_client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\tracers\\langchain.py\", line 55, in get_client\n",
      "    _CLIENT = Client()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 272, in __init__\n",
      "    _validate_api_key_if_hosted(self.api_url, self.api_key)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langsmith\\client.py\", line 181, in _validate_api_key_if_hosted\n",
      "    raise ls_utils.LangSmithUserError(\n",
      "langsmith.utils.LangSmithUserError: API key must be provided when using hosted LangSmith API\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\logging\\__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_7368\\874202668.py\", line 79, in <module>\n",
      "    chain.invoke(\"주인공의 성격을 말해줘.\")\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\schema\\runnable\\base.py\", line 1213, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 142, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 459, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\chat_models\\base.py\", line 319, in generate\n",
      "    callback_manager = CallbackManager.configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 1479, in configure\n",
      "    return _configure(\n",
      "  File \"d:\\FULLSTACK-GPT\\env\\lib\\site-packages\\langchain\\callbacks\\manager.py\", line 2075, in _configure\n",
      "    logger.warning(\n",
      "Message: 'Unable to load requested LangChainTracer. To disable this warning, unset the  LANGCHAIN_TRACING_V2 environment variables.'\n",
      "Arguments: (LangSmithUserError('API key must be provided when using hosted LangSmith API'),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='주인공인 제루샤는 근면성실하고 열심히 노력하는 모습을 보여주고 있습니다. 학업 성적이 우수하며, 두 번의 학업 과정을 성공적으로 마친 것으로 나타났습니다. 또한, 리펫 원장의 말을 따르고 긴장하는 모습이 보여지며, 미래에 대한 논의가 있을 때도 신중하게 대처하고자 하는 모습을 보여줍니다. 이를 통해 주인공은 성실하고 책임감이 강한 성격을 가지고 있을 것으로 보입니다.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.9\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# list of docs\n",
    "\n",
    "# for docs in list of docs | prompt | llm\n",
    "\n",
    "# for response in list of llms response | put them all together\n",
    "\n",
    "# final doc | prompt | llm\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Use the following portion of a long document to see\n",
    "            if any of the text is relevant to answer the question.\n",
    "            Return any relevant text verbatim.\n",
    "            -----\n",
    "            {context}\n",
    "            \"\"\"\n",
    "         ),\n",
    "         (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    print(inputs)\n",
    "    documents = inputs[\"documents\"]\n",
    "    question = inputs[\"question\"]\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(\n",
    "            {\"context\": doc.page_content, \"question\": question}\n",
    "        ).content\n",
    "        for doc in documents\n",
    "    )\n",
    "    # results = []\n",
    "    # for document in documents:\n",
    "    #     result = map_doc_chain.invoke(\n",
    "    #         {\"context\":document.page_content, \"question\":question}\n",
    "    #     ).content\n",
    "    #     results.append(result)\n",
    "    # results = \"\\n\\n\".join(results)\n",
    "    # return \"hello\"\n",
    "\n",
    "map_chain = {\n",
    "    \"documents\":retriever,\n",
    "    \"question\":RunnablePassthrough(),\n",
    "} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"\n",
    "     주어진 긴 문서와 질문에 대해 최종 정답을 알려줘.\n",
    "     만약 정답을 모른다면 모른다고 해. 정답을 만들려고 하지마.\n",
    "     -----\n",
    "     {context}\n",
    "     \"\"\",),\n",
    "     (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = {\"context\": map_chain,\"question\": RunnablePassthrough()} | final_prompt | llm\n",
    "\n",
    "chain.invoke(\"주인공의 성격을 말해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
